{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bcc3627-546c-4419-bd38-73cb5a1884eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import getpass\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd40c52-18e7-4b14-907f-a65fc272629c",
   "metadata": {},
   "source": [
    "# Importing and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5fba1a-b7a4-4832-974a-7eb930701147",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c6a0edc-2c6b-4412-8e5c-9790f84f1f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/yfq5dclx7cd6vx_pj9dj5d6m0000gn/T/ipykernel_50949/485987702.py:11: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs = [pd.read_csv(file) for file in files]\n",
      "/var/folders/kz/yfq5dclx7cd6vx_pj9dj5d6m0000gn/T/ipykernel_50949/485987702.py:11: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs = [pd.read_csv(file) for file in files]\n"
     ]
    }
   ],
   "source": [
    "def read_csv_files(*files):\n",
    "    \"\"\"\n",
    "    Read CSV files into pandas DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    files: Paths to the CSV files\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the two DataFrames (df1, df2).\n",
    "    \"\"\"\n",
    "    dfs = [pd.read_csv(file) for file in files]\n",
    "    return dfs\n",
    "\n",
    "file_paths = ['../data/Raw/dft-road-casualty-statistics-collision-2018.csv', \n",
    "              '../data/Raw/dft-road-casualty-statistics-vehicle-2018.csv',\n",
    "             '../data/Raw/dft-road-casualty-statistics-casualty-2018.csv']\n",
    "\n",
    "dataframes = read_csv_files(*file_paths)\n",
    "\n",
    "df1, df2, df3 = dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67bf89b2-43e8-4fef-a7a0-3a7f862825b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to clean all column names to allow for merging of all 4 datasets\n",
    "def column_cleaning(dfs):\n",
    "    for i in range(len(dfs)):\n",
    "        dfs[i].columns = dfs[i].columns.str.strip().str.lower()\n",
    "        if 'row_id' in dfs[i].columns:\n",
    "            dfs[i] = dfs[i].drop(columns=['row_id'])\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a74dc8c-daa6-4fe9-9e9e-f1a3edcc99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the function to the 4 datasets\n",
    "df1, df2, df3 = column_cleaning([df1, df2, df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbe730e9-8cdf-453c-afb1-86ab40c6c8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accident_index</th>\n",
       "      <th>accident_year</th>\n",
       "      <th>accident_reference</th>\n",
       "      <th>location_easting_osgr</th>\n",
       "      <th>location_northing_osgr</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>police_force</th>\n",
       "      <th>accident_severity</th>\n",
       "      <th>number_of_vehicles</th>\n",
       "      <th>...</th>\n",
       "      <th>pedestrian_crossing_physical_facilities</th>\n",
       "      <th>light_conditions</th>\n",
       "      <th>weather_conditions</th>\n",
       "      <th>road_surface_conditions</th>\n",
       "      <th>special_conditions_at_site</th>\n",
       "      <th>carriageway_hazards</th>\n",
       "      <th>urban_or_rural_area</th>\n",
       "      <th>did_police_officer_attend_scene_of_accident</th>\n",
       "      <th>trunk_road_flag</th>\n",
       "      <th>lsoa_of_accident_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018010080971</td>\n",
       "      <td>2018</td>\n",
       "      <td>10080971</td>\n",
       "      <td>529150.0</td>\n",
       "      <td>182270.0</td>\n",
       "      <td>-0.139737</td>\n",
       "      <td>51.524587</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>E01000854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  accident_index  accident_year accident_reference  location_easting_osgr  \\\n",
       "0  2018010080971           2018           10080971               529150.0   \n",
       "\n",
       "   location_northing_osgr  longitude   latitude  police_force  \\\n",
       "0                182270.0  -0.139737  51.524587             1   \n",
       "\n",
       "   accident_severity  number_of_vehicles  ...  \\\n",
       "0                  3                   2  ...   \n",
       "\n",
       "   pedestrian_crossing_physical_facilities light_conditions  \\\n",
       "0                                        0                4   \n",
       "\n",
       "   weather_conditions road_surface_conditions  special_conditions_at_site  \\\n",
       "0                   1                       1                           0   \n",
       "\n",
       "  carriageway_hazards urban_or_rural_area  \\\n",
       "0                   0                   1   \n",
       "\n",
       "   did_police_officer_attend_scene_of_accident  trunk_road_flag  \\\n",
       "0                                            1                2   \n",
       "\n",
       "   lsoa_of_accident_location  \n",
       "0                  E01000854  \n",
       "\n",
       "[1 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48a1bc19-fd75-4bf6-98df-df33a595e791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accident_index</th>\n",
       "      <th>accident_year</th>\n",
       "      <th>accident_reference</th>\n",
       "      <th>vehicle_reference</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>towing_and_articulation</th>\n",
       "      <th>vehicle_manoeuvre</th>\n",
       "      <th>vehicle_direction_from</th>\n",
       "      <th>vehicle_direction_to</th>\n",
       "      <th>vehicle_location_restricted_lane</th>\n",
       "      <th>...</th>\n",
       "      <th>sex_of_driver</th>\n",
       "      <th>age_of_driver</th>\n",
       "      <th>age_band_of_driver</th>\n",
       "      <th>engine_capacity_cc</th>\n",
       "      <th>propulsion_code</th>\n",
       "      <th>age_of_vehicle</th>\n",
       "      <th>generic_make_model</th>\n",
       "      <th>driver_imd_decile</th>\n",
       "      <th>driver_home_area_type</th>\n",
       "      <th>lsoa_of_driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018010080971</td>\n",
       "      <td>2018</td>\n",
       "      <td>10080971</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>1995</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>BMW 5 SERIES</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>E01011051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  accident_index  accident_year accident_reference  vehicle_reference  \\\n",
       "0  2018010080971           2018           10080971                  1   \n",
       "\n",
       "   vehicle_type  towing_and_articulation  vehicle_manoeuvre  \\\n",
       "0             9                        0                 18   \n",
       "\n",
       "   vehicle_direction_from  vehicle_direction_to  \\\n",
       "0                       3                     7   \n",
       "\n",
       "   vehicle_location_restricted_lane  ...  sex_of_driver  age_of_driver  \\\n",
       "0                                 0  ...              1             32   \n",
       "\n",
       "   age_band_of_driver  engine_capacity_cc  propulsion_code  age_of_vehicle  \\\n",
       "0                   6                1995                2               5   \n",
       "\n",
       "   generic_make_model  driver_imd_decile  driver_home_area_type  \\\n",
       "0        BMW 5 SERIES                  8                      1   \n",
       "\n",
       "   lsoa_of_driver  \n",
       "0       E01011051  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f58199d8-7d6e-4ab5-a397-c48ad2fe9e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accident_index</th>\n",
       "      <th>accident_year</th>\n",
       "      <th>accident_reference</th>\n",
       "      <th>vehicle_reference</th>\n",
       "      <th>casualty_reference</th>\n",
       "      <th>casualty_class</th>\n",
       "      <th>sex_of_casualty</th>\n",
       "      <th>age_of_casualty</th>\n",
       "      <th>age_band_of_casualty</th>\n",
       "      <th>casualty_severity</th>\n",
       "      <th>pedestrian_location</th>\n",
       "      <th>pedestrian_movement</th>\n",
       "      <th>car_passenger</th>\n",
       "      <th>bus_or_coach_passenger</th>\n",
       "      <th>pedestrian_road_maintenance_worker</th>\n",
       "      <th>casualty_type</th>\n",
       "      <th>casualty_home_area_type</th>\n",
       "      <th>casualty_imd_decile</th>\n",
       "      <th>lsoa_of_casualty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018010080971</td>\n",
       "      <td>2018</td>\n",
       "      <td>010080971</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>E01011051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accident_index  accident_year accident_reference  vehicle_reference  \\\n",
       "0  2018010080971           2018          010080971                  1   \n",
       "\n",
       "   casualty_reference  casualty_class  sex_of_casualty  age_of_casualty  \\\n",
       "0                   1               2                2               50   \n",
       "\n",
       "   age_band_of_casualty  casualty_severity  pedestrian_location  \\\n",
       "0                     8                  3                    0   \n",
       "\n",
       "   pedestrian_movement  car_passenger  bus_or_coach_passenger  \\\n",
       "0                    0              2                       0   \n",
       "\n",
       "   pedestrian_road_maintenance_worker  casualty_type  casualty_home_area_type  \\\n",
       "0                                   0              9                        1   \n",
       "\n",
       "   casualty_imd_decile lsoa_of_casualty  \n",
       "0                    8        E01011051  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a642f9f8-98b4-4fe7-aa21-82354b0bc042",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47699691-2a3c-43be-9112-d3493d3f9ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accident_index', 'accident_year', 'accident_reference',\n",
       "       'location_easting_osgr', 'location_northing_osgr', 'longitude',\n",
       "       'latitude', 'police_force', 'accident_severity', 'number_of_vehicles',\n",
       "       'number_of_casualties', 'date', 'day_of_week', 'time',\n",
       "       'local_authority_district', 'local_authority_ons_district',\n",
       "       'local_authority_highway', 'first_road_class', 'first_road_number',\n",
       "       'road_type', 'speed_limit', 'junction_detail', 'junction_control',\n",
       "       'second_road_class', 'second_road_number',\n",
       "       'pedestrian_crossing_human_control',\n",
       "       'pedestrian_crossing_physical_facilities', 'light_conditions',\n",
       "       'weather_conditions', 'road_surface_conditions',\n",
       "       'special_conditions_at_site', 'carriageway_hazards',\n",
       "       'urban_or_rural_area', 'did_police_officer_attend_scene_of_accident',\n",
       "       'trunk_road_flag', 'lsoa_of_accident_location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b469d28-80a0-4881-a379-07b69a19aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_to_keep_collision(df):\n",
    "    \"\"\"\n",
    "    There are several columns that are not relevant for the analysis and therefore will be removed\n",
    "    from the dataset.\n",
    "    \"\"\"\n",
    "    columns_to_keep = ['accident_index', 'accident_year', 'longitude', 'latitude', 'accident_severity', 'date', \n",
    "                       'day_of_week', 'time', 'local_authority_ons_district']\n",
    "\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    return df\n",
    "\n",
    "df1 = columns_to_keep_collision(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f966e8df-308f-4a80-a2df-80a05a9afdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accident_index', 'accident_year', 'accident_reference',\n",
       "       'vehicle_reference', 'vehicle_type', 'towing_and_articulation',\n",
       "       'vehicle_manoeuvre', 'vehicle_direction_from', 'vehicle_direction_to',\n",
       "       'vehicle_location_restricted_lane', 'junction_location',\n",
       "       'skidding_and_overturning', 'hit_object_in_carriageway',\n",
       "       'vehicle_leaving_carriageway', 'hit_object_off_carriageway',\n",
       "       'first_point_of_impact', 'vehicle_left_hand_drive',\n",
       "       'journey_purpose_of_driver', 'sex_of_driver', 'age_of_driver',\n",
       "       'age_band_of_driver', 'engine_capacity_cc', 'propulsion_code',\n",
       "       'age_of_vehicle', 'generic_make_model', 'driver_imd_decile',\n",
       "       'driver_home_area_type', 'lsoa_of_driver'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdae126c-a9b9-4cfd-9033-cbceb03e95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_to_keep_vehicle(df):\n",
    "    \"\"\"\n",
    "    There are also several columns in the vehicle dataset that will need to be removed as they will not be\n",
    "    relevant in the analysis.\n",
    "    \"\"\"\n",
    "    columns_to_keep = ['accident_index', 'vehicle_type', 'sex_of_driver', 'age_band_of_driver']\n",
    "\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    return df\n",
    "\n",
    "df2 = columns_to_keep_vehicle(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bae48c4c-0f6e-47f4-9c7c-77b0c1d877bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accident_index', 'accident_year', 'accident_reference',\n",
       "       'vehicle_reference', 'casualty_reference', 'casualty_class',\n",
       "       'sex_of_casualty', 'age_of_casualty', 'age_band_of_casualty',\n",
       "       'casualty_severity', 'pedestrian_location', 'pedestrian_movement',\n",
       "       'car_passenger', 'bus_or_coach_passenger',\n",
       "       'pedestrian_road_maintenance_worker', 'casualty_type',\n",
       "       'casualty_home_area_type', 'casualty_imd_decile', 'lsoa_of_casualty'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ec2a5c6-e4c7-4ada-9542-76b3c7fbf38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_to_keep_casualty(df):\n",
    "    columns_to_keep = ['accident_index', 'casualty_class', 'sex_of_casualty', 'age_band_of_casualty', 'casualty_severity']\n",
    "    df = df[columns_to_keep]\n",
    "    return df\n",
    "\n",
    "df3 = columns_to_keep_casualty(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "874ca6a5-90cd-484d-81aa-9936fd4aac73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/yfq5dclx7cd6vx_pj9dj5d6m0000gn/T/ipykernel_50949/485987702.py:11: DtypeWarning: Columns (0,2,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs = [pd.read_csv(file) for file in files]\n",
      "/var/folders/kz/yfq5dclx7cd6vx_pj9dj5d6m0000gn/T/ipykernel_50949/485987702.py:11: DtypeWarning: Columns (0,2,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs = [pd.read_csv(file) for file in files]\n",
      "/var/folders/kz/yfq5dclx7cd6vx_pj9dj5d6m0000gn/T/ipykernel_50949/485987702.py:11: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs = [pd.read_csv(file) for file in files]\n",
      "/var/folders/kz/yfq5dclx7cd6vx_pj9dj5d6m0000gn/T/ipykernel_50949/485987702.py:11: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs = [pd.read_csv(file) for file in files]\n",
      "/var/folders/kz/yfq5dclx7cd6vx_pj9dj5d6m0000gn/T/ipykernel_50949/485987702.py:11: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs = [pd.read_csv(file) for file in files]\n",
      "/var/folders/kz/yfq5dclx7cd6vx_pj9dj5d6m0000gn/T/ipykernel_50949/485987702.py:11: DtypeWarning: Columns (0,2,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs = [pd.read_csv(file) for file in files]\n",
      "/var/folders/kz/yfq5dclx7cd6vx_pj9dj5d6m0000gn/T/ipykernel_50949/485987702.py:11: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs = [pd.read_csv(file) for file in files]\n",
      "/var/folders/kz/yfq5dclx7cd6vx_pj9dj5d6m0000gn/T/ipykernel_50949/485987702.py:11: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs = [pd.read_csv(file) for file in files]\n",
      "/var/folders/kz/yfq5dclx7cd6vx_pj9dj5d6m0000gn/T/ipykernel_50949/485987702.py:11: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs = [pd.read_csv(file) for file in files]\n",
      "/var/folders/kz/yfq5dclx7cd6vx_pj9dj5d6m0000gn/T/ipykernel_50949/485987702.py:11: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs = [pd.read_csv(file) for file in files]\n",
      "/var/folders/kz/yfq5dclx7cd6vx_pj9dj5d6m0000gn/T/ipykernel_50949/485987702.py:11: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs = [pd.read_csv(file) for file in files]\n"
     ]
    }
   ],
   "source": [
    "#Lets load dataset for 2019, 2020, 2021, and 2022\n",
    "file_path = ['../data/Raw/dft-road-casualty-statistics-collision-2019.csv',\n",
    "             '../data/Raw/dft-road-casualty-statistics-vehicle-2019.csv',\n",
    "             '../data/Raw/dft-road-casualty-statistics-casualty-2019.csv',\n",
    "             '../data/Raw/dft-road-casualty-statistics-collision-2020.csv',\n",
    "             '../data/Raw/dft-road-casualty-statistics-vehicle-2020.csv',\n",
    "             '../data/Raw/dft-road-casualty-statistics-casualty-2020.csv',\n",
    "             '../data/Raw/dft-road-casualty-statistics-collision-2021.csv',\n",
    "             '../data/Raw/dft-road-casualty-statistics-vehicle-2021.csv',\n",
    "             '../data/Raw/dft-road-casualty-statistics-casualty-2021.csv',\n",
    "             '../data/Raw/dft-road-casualty-statistics-collision-2022.csv',\n",
    "             '../data/Raw/dft-road-casualty-statistics-vehicle-2022.csv',\n",
    "             '../data/Raw/dft-road-casualty-statistics-casualty-2022.csv']\n",
    "\n",
    "dataframe = read_csv_files(*file_path)\n",
    "\n",
    "df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14, df15 = dataframe\n",
    "\n",
    "#Clean columns of all datasets\n",
    "df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14, df15 = column_cleaning([df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14, df15])\n",
    "\n",
    "#Keep only the relevant columns for the collision datasets\n",
    "df4 = columns_to_keep_collision(df4)\n",
    "df7 = columns_to_keep_collision(df7)\n",
    "df10 = columns_to_keep_collision(df10)\n",
    "df13 = columns_to_keep_collision(df13)\n",
    "\n",
    "#Keep only the relevant columns for the vehicle datasets\n",
    "df5 = columns_to_keep_vehicle(df5)\n",
    "df8 = columns_to_keep_vehicle(df8)\n",
    "df11 = columns_to_keep_vehicle(df11)\n",
    "df14 = columns_to_keep_vehicle(df14)\n",
    "\n",
    "#Keep only the relevant columns for the casualty datasets\n",
    "df6 = columns_to_keep_casualty(df6)\n",
    "df9 = columns_to_keep_casualty(df9)\n",
    "df12 = columns_to_keep_casualty(df12)\n",
    "df15 = columns_to_keep_casualty(df15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa26669d-75c8-43b2-9292-c4b8e0cbb760",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets now concatenate all 'collision', 'vehicle', and 'casualty' dataset together from different years\n",
    "collision = pd.concat([df1, df4, df7, df10, df13], axis = 0)\n",
    "vehicle = pd.concat([df2, df5, df8, df11, df14], axis = 0)\n",
    "casualty = pd.concat([df3, df6, df9, df12, df15], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3a4f19f-5606-4cff-870a-219ea87eb872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accident_index</th>\n",
       "      <th>accident_year</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>accident_severity</th>\n",
       "      <th>date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time</th>\n",
       "      <th>local_authority_ons_district</th>\n",
       "      <th>local_authority_district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018010080971</td>\n",
       "      <td>2018</td>\n",
       "      <td>-0.139737</td>\n",
       "      <td>51.524587</td>\n",
       "      <td>3</td>\n",
       "      <td>01/01/2018</td>\n",
       "      <td>2</td>\n",
       "      <td>01:30</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018010080973</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.046471</td>\n",
       "      <td>51.539651</td>\n",
       "      <td>3</td>\n",
       "      <td>01/01/2018</td>\n",
       "      <td>2</td>\n",
       "      <td>00:50</td>\n",
       "      <td>E09000025</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018010080974</td>\n",
       "      <td>2018</td>\n",
       "      <td>-0.102474</td>\n",
       "      <td>51.529746</td>\n",
       "      <td>3</td>\n",
       "      <td>01/01/2018</td>\n",
       "      <td>2</td>\n",
       "      <td>00:45</td>\n",
       "      <td>E09000019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018010080981</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.037828</td>\n",
       "      <td>51.530179</td>\n",
       "      <td>2</td>\n",
       "      <td>01/01/2018</td>\n",
       "      <td>2</td>\n",
       "      <td>03:00</td>\n",
       "      <td>E09000025</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018010080982</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.065781</td>\n",
       "      <td>51.469258</td>\n",
       "      <td>2</td>\n",
       "      <td>01/01/2018</td>\n",
       "      <td>2</td>\n",
       "      <td>02:20</td>\n",
       "      <td>E09000011</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105999</th>\n",
       "      <td>2022991311627</td>\n",
       "      <td>2022</td>\n",
       "      <td>-4.613246</td>\n",
       "      <td>55.495815</td>\n",
       "      <td>2</td>\n",
       "      <td>24/12/2022</td>\n",
       "      <td>7</td>\n",
       "      <td>15:00</td>\n",
       "      <td>S12000028</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106000</th>\n",
       "      <td>2022991312498</td>\n",
       "      <td>2022</td>\n",
       "      <td>-6.348650</td>\n",
       "      <td>55.783849</td>\n",
       "      <td>2</td>\n",
       "      <td>12/11/2022</td>\n",
       "      <td>7</td>\n",
       "      <td>21:35</td>\n",
       "      <td>S12000035</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106001</th>\n",
       "      <td>2022991315177</td>\n",
       "      <td>2022</td>\n",
       "      <td>-4.326930</td>\n",
       "      <td>55.843114</td>\n",
       "      <td>3</td>\n",
       "      <td>01/07/2022</td>\n",
       "      <td>6</td>\n",
       "      <td>11:44</td>\n",
       "      <td>S12000049</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106002</th>\n",
       "      <td>2022991321308</td>\n",
       "      <td>2022</td>\n",
       "      <td>-3.196963</td>\n",
       "      <td>55.980648</td>\n",
       "      <td>2</td>\n",
       "      <td>02/12/2022</td>\n",
       "      <td>6</td>\n",
       "      <td>16:45</td>\n",
       "      <td>S12000036</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106003</th>\n",
       "      <td>2022991322411</td>\n",
       "      <td>2022</td>\n",
       "      <td>-3.206662</td>\n",
       "      <td>55.950381</td>\n",
       "      <td>2</td>\n",
       "      <td>23/11/2022</td>\n",
       "      <td>4</td>\n",
       "      <td>19:05</td>\n",
       "      <td>S12000036</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538461 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accident_index  accident_year  longitude   latitude  accident_severity  \\\n",
       "0       2018010080971           2018  -0.139737  51.524587                  3   \n",
       "1       2018010080973           2018   0.046471  51.539651                  3   \n",
       "2       2018010080974           2018  -0.102474  51.529746                  3   \n",
       "3       2018010080981           2018   0.037828  51.530179                  2   \n",
       "4       2018010080982           2018   0.065781  51.469258                  2   \n",
       "...               ...            ...        ...        ...                ...   \n",
       "105999  2022991311627           2022  -4.613246  55.495815                  2   \n",
       "106000  2022991312498           2022  -6.348650  55.783849                  2   \n",
       "106001  2022991315177           2022  -4.326930  55.843114                  3   \n",
       "106002  2022991321308           2022  -3.196963  55.980648                  2   \n",
       "106003  2022991322411           2022  -3.206662  55.950381                  2   \n",
       "\n",
       "              date  day_of_week   time local_authority_ons_district  \\\n",
       "0       01/01/2018            2  01:30                    E09000007   \n",
       "1       01/01/2018            2  00:50                    E09000025   \n",
       "2       01/01/2018            2  00:45                    E09000019   \n",
       "3       01/01/2018            2  03:00                    E09000025   \n",
       "4       01/01/2018            2  02:20                    E09000011   \n",
       "...            ...          ...    ...                          ...   \n",
       "105999  24/12/2022            7  15:00                    S12000028   \n",
       "106000  12/11/2022            7  21:35                    S12000035   \n",
       "106001  01/07/2022            6  11:44                    S12000049   \n",
       "106002  02/12/2022            6  16:45                    S12000036   \n",
       "106003  23/11/2022            4  19:05                    S12000036   \n",
       "\n",
       "        local_authority_district  \n",
       "0                              2  \n",
       "1                             17  \n",
       "2                              3  \n",
       "3                             17  \n",
       "4                              6  \n",
       "...                          ...  \n",
       "105999                        -1  \n",
       "106000                        -1  \n",
       "106001                        -1  \n",
       "106002                        -1  \n",
       "106003                        -1  \n",
       "\n",
       "[538461 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b117a0e9-3b08-467f-9704-6280a0cc404e",
   "metadata": {},
   "source": [
    "#### Collision Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09dcbfbd-1ea3-4d8d-b810-3daae2d04389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 538461 entries, 0 to 106003\n",
      "Data columns (total 10 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   accident_index                538461 non-null  object \n",
      " 1   accident_year                 538461 non-null  int64  \n",
      " 2   longitude                     538325 non-null  float64\n",
      " 3   latitude                      538325 non-null  float64\n",
      " 4   accident_severity             538461 non-null  int64  \n",
      " 5   date                          538461 non-null  object \n",
      " 6   day_of_week                   538461 non-null  int64  \n",
      " 7   time                          538461 non-null  object \n",
      " 8   local_authority_ons_district  538461 non-null  object \n",
      " 9   local_authority_district      538461 non-null  int64  \n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 45.2+ MB\n"
     ]
    }
   ],
   "source": [
    "collision.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7db66f42-42a1-4271-a252-ced6ef1adbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "collision['longitude'] = collision['longitude'].fillna('0.000000')\n",
    "collision['latitude'] = collision['latitude'].fillna('0.000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6b4f30b-63fd-4dbf-9f72-a316fbf89484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 538461 entries, 0 to 106003\n",
      "Data columns (total 10 columns):\n",
      " #   Column                        Non-Null Count   Dtype \n",
      "---  ------                        --------------   ----- \n",
      " 0   accident_index                538461 non-null  object\n",
      " 1   accident_year                 538461 non-null  int64 \n",
      " 2   longitude                     538461 non-null  object\n",
      " 3   latitude                      538461 non-null  object\n",
      " 4   accident_severity             538461 non-null  int64 \n",
      " 5   date                          538461 non-null  object\n",
      " 6   day_of_week                   538461 non-null  int64 \n",
      " 7   time                          538461 non-null  object\n",
      " 8   local_authority_ons_district  538461 non-null  object\n",
      " 9   local_authority_district      538461 non-null  int64 \n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 45.2+ MB\n"
     ]
    }
   ],
   "source": [
    "collision.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae844956-852b-4218-b0f3-4a863b7fa5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accident_index', 'accident_year', 'longitude', 'latitude',\n",
       "       'accident_severity', 'date', 'day_of_week', 'time',\n",
       "       'local_authority_ons_district', 'local_authority_district'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa86a8fe-8465-477d-b739-afc77422cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_accident_severity(df):\n",
    "    \"\"\"\n",
    "    Clean the 'accident_severity' column by replacing the numbers with a categorical variable to give it some meaning.'\n",
    "    \"\"\"\n",
    "    \n",
    "    #Mapping dictionary to regroup accident severity \n",
    "    accident_severity_mapping = {\n",
    "        1.0:'fatal',\n",
    "        2.0:'Seriously Injuries',\n",
    "        3.0:'Minor Injuries'\n",
    "    }\n",
    "\n",
    "    #Map values using the mapping dictionary\n",
    "    df['accident_severity'] = df['accident_severity'].map(accident_severity_mapping)\n",
    "\n",
    "    return df\n",
    "collision = clean_accident_severity(collision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ea6e2a4-063a-458e-b2e3-9fa16e134d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the 'date' column to datetime type\n",
    "collision['date'] = pd.to_datetime(collision['date'], format='%d/%m/%Y')\n",
    "\n",
    "#Create a 'month' column by extracting the month from the 'date' column\n",
    "collision['accident_month'] = collision['date'].dt.month\n",
    "\n",
    "def clean_accident_month(df):\n",
    "    \"\"\"\n",
    "    Now that we have extracted the month in which the accident took place, lets rename the variables and convert them from numbers into the month names\n",
    "    \"\"\"\n",
    "    accident_month_mapping = {\n",
    "    1:'January',\n",
    "    2:'February',\n",
    "    3:'March',\n",
    "    4:'April',\n",
    "    5:'May',\n",
    "    6:'June',\n",
    "    7:'July',\n",
    "    8:'August',\n",
    "    9:'September',\n",
    "    10:'October',\n",
    "    11:'November',\n",
    "    12:'December'\n",
    "    }\n",
    "\n",
    "    df['accident_month'] = df['accident_month'].map(accident_month_mapping)\n",
    "\n",
    "    return df\n",
    "\n",
    "collision = clean_accident_month(collision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "777bd093-06f2-4267-be58-693b2ce12564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_day_of_week(df):\n",
    "    \"\"\"\n",
    "    Clean the 'day_of_week' column by replacing the numbers with the days of the week for easier understanding.'\n",
    "    \"\"\"\n",
    "    \n",
    "    #Mapping dictionary to regroup day of the week \n",
    "    day_of_week_mapping = {\n",
    "        1.0:'Sunday',\n",
    "        2.0:'Monday',\n",
    "        3.0:'Tuesday',\n",
    "        4.0:'Wednesday',\n",
    "        5.0:'Thursday',\n",
    "        6.0:'Friday',\n",
    "        7.0:'Saturday'\n",
    "    }\n",
    "\n",
    "    #Map values using the mapping dictionary\n",
    "    df['day_of_week'] = df['day_of_week'].map(day_of_week_mapping)\n",
    "\n",
    "    return df\n",
    "\n",
    "collision = clean_day_of_week(collision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc6c2bd0-739b-4fbc-a6a0-fde1633a79df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E09000007', 'E09000025', 'E09000019', 'E09000011', 'E09000003',\n",
       "       'E09000020', 'E09000023', 'E09000005', 'E09000030', 'E09000018',\n",
       "       'E09000015', 'E09000028', 'E09000022', 'E09000009', 'E09000032',\n",
       "       'E09000012', 'E09000014', 'E09000027', 'E09000010', 'E09000029',\n",
       "       'E09000031', 'E09000026', 'E09000013', 'E09000002', 'E09000024',\n",
       "       'E09000008', 'E09000017', 'E09000016', 'E09000006', 'E09000033',\n",
       "       'E09000004', 'E09000021', 'EHEATHROW', 'E09000001', 'E07000028',\n",
       "       'E07000026', 'E07000031', 'E07000027', 'E07000030', 'E07000029',\n",
       "       'E06000009', 'E06000008', 'E07000120', 'E07000124', 'E07000126',\n",
       "       'E07000117', 'E07000125', 'E07000122', 'E07000123', 'E07000118',\n",
       "       'E07000127', 'E07000119', 'E07000121', 'E07000128', 'E08000011',\n",
       "       'E08000012', 'E08000015', 'E08000014', 'E08000013', 'E08000003',\n",
       "       'E08000006', 'E08000008', 'E08000007', 'E08000001', 'E08000010',\n",
       "       'E08000009', 'E08000002', 'E08000005', 'E08000004', 'E06000007',\n",
       "       'E06000049', 'E06000050', 'E06000006', 'E08000021', 'E06000057',\n",
       "       'E08000022', 'E08000023', 'E08000024', 'E08000037', 'E06000047',\n",
       "       'E06000005', 'E07000169', 'E07000165', 'E07000164', 'E06000014',\n",
       "       'E07000163', 'E07000166', 'E07000168', 'E07000167', 'E08000036',\n",
       "       'E08000035', 'E08000032', 'E08000034', 'E08000033', 'E08000019',\n",
       "       'E08000016', 'E08000017', 'E08000018', 'E06000010', 'E06000012',\n",
       "       'E06000011', 'E06000013', 'E06000001', 'E06000003', 'E06000002',\n",
       "       'E06000004', 'E08000028', 'E08000026', 'E08000025', 'E08000030',\n",
       "       'E08000027', 'E08000031', 'E08000029', 'E07000198', 'E07000197',\n",
       "       'E07000196', 'E07000199', 'E07000194', 'E07000193', 'E07000195',\n",
       "       'E07000192', 'E06000021', 'E07000235', 'E06000051', 'E07000237',\n",
       "       'E06000019', 'E06000020', 'E07000238', 'E07000236', 'E07000234',\n",
       "       'E07000239', 'E07000218', 'E07000219', 'E07000222', 'E07000221',\n",
       "       'E07000220', 'E07000038', 'E06000015', 'E07000036', 'E07000039',\n",
       "       'E07000037', 'E07000032', 'E07000034', 'E07000033', 'E07000035',\n",
       "       'E07000170', 'E07000174', 'E07000175', 'E07000171', 'E06000018',\n",
       "       'E07000172', 'E07000173', 'E07000176', 'E07000137', 'E07000141',\n",
       "       'E07000136', 'E07000139', 'E07000142', 'E07000138', 'E07000140',\n",
       "       'E06000016', 'E07000130', 'E07000135', 'E07000134', 'E06000017',\n",
       "       'E07000131', 'E07000132', 'E07000129', 'E07000133', 'E07000150',\n",
       "       'E07000152', 'E07000153', 'E07000151', 'E07000155', 'E07000156',\n",
       "       'E07000154', 'E07000011', 'E07000012', 'E07000008', 'E07000009',\n",
       "       'E06000031', 'E07000010', 'E07000148', 'E07000146', 'E07000147',\n",
       "       'E07000143', 'E07000144', 'E07000149', 'E07000145', 'E07000200',\n",
       "       'E07000204', 'E07000202', 'E07000205', 'E07000203', 'E07000201',\n",
       "       'E07000206', 'E06000032', 'E06000055', 'E06000056', 'E07000242',\n",
       "       'E07000096', 'E07000099', 'E07000243', 'E07000241', 'E07000095',\n",
       "       'E07000103', 'E07000098', 'E07000102', 'E07000240', 'E06000034',\n",
       "       'E07000071', 'E07000072', 'E07000077', 'E06000033', 'E07000076',\n",
       "       'E07000066', 'E07000068', 'E07000070', 'E07000069', 'E07000075',\n",
       "       'E07000074', 'E07000067', 'E07000073', 'E07000177', 'E06000038',\n",
       "       'E06000042', 'E07000007', 'E06000037', 'E06000040', 'E07000179',\n",
       "       'E07000181', 'E07000178', 'E07000180', 'E07000004', 'E07000006',\n",
       "       'E06000039', 'E06000041', 'E06000036', 'E07000005', 'E07000108',\n",
       "       'E07000091', 'E07000086', 'E06000044', 'E07000084', 'E07000085',\n",
       "       'E06000045', 'E07000090', 'E07000087', 'E07000089', 'E07000088',\n",
       "       'E06000046', 'E07000093', 'E07000094', 'E07000092', 'E07000208',\n",
       "       'E07000209', 'E07000210', 'E07000212', 'E07000211', 'E07000207',\n",
       "       'E07000214', 'E07000215', 'E07000217', 'E07000213', 'E07000216',\n",
       "       'E06000035', 'E07000114', 'E07000111', 'E07000113', 'E07000112',\n",
       "       'E07000115', 'E07000116', 'E07000105', 'E07000109', 'E07000106',\n",
       "       'E07000107', 'E07000110', 'E06000043', 'E07000223', 'E07000228',\n",
       "       'E07000064', 'E07000063', 'E07000227', 'E07000226', 'E07000062',\n",
       "       'E07000061', 'E07000229', 'E07000225', 'E07000224', 'E07000065',\n",
       "       'E06000052', 'E07000044', 'E06000026', 'E07000046', 'E07000040',\n",
       "       'E07000045', 'E07000041', 'E07000047', 'E06000027', 'E07000043',\n",
       "       'E07000042', 'E06000053', 'E07000190', 'E07000191', 'E07000188',\n",
       "       'E07000189', 'E07000187', 'E06000024', 'E06000023', 'E06000022',\n",
       "       'E06000025', 'E07000083', 'E07000082', 'E07000079', 'E07000078',\n",
       "       'E07000080', 'E07000081', 'E06000054', 'E06000030', 'E06000029',\n",
       "       'E07000052', 'E07000053', 'E06000028', 'E07000051', 'E07000049',\n",
       "       'E07000048', 'E07000050', 'W06000004', 'W06000006', 'W06000005',\n",
       "       'W06000002', 'W06000003', 'W06000001', 'W06000018', 'W06000022',\n",
       "       'W06000019', 'W06000021', 'W06000020', 'W06000015', 'W06000016',\n",
       "       'W06000024', 'W06000011', 'W06000012', 'W06000014', 'W06000013',\n",
       "       'W06000010', 'W06000008', 'W06000009', 'W06000023', 'S12000017',\n",
       "       'S12000013', 'S12000027', 'S12000023', 'S12000033', 'S12000034',\n",
       "       'S12000020', 'S12000048', 'S12000041', 'S12000042', 'S12000047',\n",
       "       'S12000036', 'S12000019', 'S12000040', 'S12000026', 'S12000010',\n",
       "       'S12000014', 'S12000030', 'S12000005', 'S12000049', 'S12000038',\n",
       "       'S12000011', 'S12000045', 'S12000018', 'S12000035', 'S12000039',\n",
       "       'S12000050', 'S12000029', 'S12000021', 'S12000008', 'S12000028',\n",
       "       'S12000006', 'E06000059', 'E06000058', 'E07000244', 'E07000245',\n",
       "       'E06000060', 'E06000062', 'E06000061'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision['local_authority_ons_district'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fad6e5e-77b4-46a5-9ecb-e1ecaa9ad551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using map, lets convert the 'local_authority_ons_district' column to its district.\n",
    "uk_admin_areas = {\n",
    "    \"E06000001\": \"Hartlepool\", \"E06000002\": \"Middlesbrough\", \"E06000003\": \"Redcar and Cleveland\", \"E06000004\": \"Stockton-on-Tees\",\n",
    "    \"E06000005\": \"Darlington\", \"E06000006\": \"Halton\", \"E06000007\": \"Warrington\", \"E06000008\": \"Blackburn with Darwen\", \n",
    "    \"E06000009\": \"Blackpool\", \"E06000010\": \"Kingston upon Hull, City of\", \"E06000011\": \"East Riding of Yorkshire\", \n",
    "    \"E06000012\": \"North East Lincolnshire\", \"E06000013\": \"North Lincolnshire\", \"E06000014\": \"York\", \"E06000015\": \"Derby\",\n",
    "    \"E06000016\": \"Leicester\", \"E06000017\": \"Rutland\", \"E06000018\": \"Nottingham\", \"E06000019\": \"Herefordshire, County of\",\n",
    "    \"E06000020\": \"Telford and Wrekin\", \"E06000021\": \"Stoke-on-Trent\", \"E06000022\": \"Bath and North East Somerset\", \n",
    "    \"E06000023\": \"Bristol, City of\", \"E06000024\": \"North Somerset\", \"E06000025\": \"South Gloucestershire\", \"E06000026\": \"Plymouth\",\n",
    "    \"E06000027\": \"Torbay\", \"E06000028\": \"Bournemouth\", \"E06000029\": \"Poole\", \"E06000030\": \"Swindon\", \"E06000031\": \"Peterborough\",\n",
    "    \"E06000032\": \"Luton\", \"E06000033\": \"Southend-on-Sea\", \"E06000034\": \"Thurrock\", \"E06000035\": \"Medway\", \"E06000036\": \"Bracknell Forest\",\n",
    "    \"E06000037\": \"West Berkshire\", \"E06000038\": \"Reading\", \"E06000039\": \"Slough\", \"E06000040\": \"Windsor and Maidenhead\", \n",
    "    \"E06000041\": \"Wokingham\", \"E06000042\": \"Milton Keynes\", \"E06000043\": \"Brighton and Hove\", \"E06000044\": \"Portsmouth\",\n",
    "    \"E06000045\": \"Southampton\", \"E06000046\": \"Isle of Wight\", \"E06000047\": \"County Durham\", \"E06000048\": \"Northumberland\",\n",
    "    \"E06000049\": \"Cheshire East\", \"E06000050\": \"Cheshire West and Chester\", \"E06000051\": \"Shropshire\", \"E06000052\": \"Cornwall\",\n",
    "    \"E06000053\": \"Isles of Scilly\", \"E06000054\": \"Wiltshire\", \"E06000055\": \"Bedford\", \"E06000056\": \"Central Bedfordshire\",\n",
    "    \"E06000057\": \"Northumberland\", \"E06000058\": \"Bournemouth, Christchurch and Poole\", \"E06000059\": \"Dorset (excluding Christchurch)\",\n",
    "    \"E06000060\": \"Buckinghamshire\", \"E06000061\": \"North Northamptonshire\", \"E06000062\": \"West Northamptonshire\", \"E07000001\": \"Mid Bedfordshire\",\n",
    "    \"E07000002\": \"Bedford\", \"E07000003\": \"South Bedfordshire\", \"E07000004\": \"Aylesbury Vale\", \"E07000005\": \"Chiltern\", \"E07000006\": \"South Bucks\",\n",
    "    \"E07000007\": \"Wycombe\", \"E07000008\": \"Cambridge\", \"E07000009\": \"East Cambridgeshire\", \"E07000010\": \"Fenland\", \"E07000011\": \"Huntingdonshire\",\n",
    "    \"E07000012\": \"South Cambridgeshire\", \"E07000019\": \"Caradon\", \"E07000020\": \"Carrick\", \"E07000021\": \"Kerrier\", \"E07000022\": \"North Cornwall\",\n",
    "    \"E07000023\": \"Penwith\", \"E07000024\": \"Restormel\", \"E07000026\": \"Allerdale\", \"E07000027\": \"Barrow-in-Furness\", \"E07000028\": \"Carlisle\",\n",
    "    \"E07000029\": \"Copeland\", \"E07000030\": \"Eden\", \"E07000031\": \"South Lakeland\", \"E07000032\": \"Amber Valley\", \"E07000033\": \"Bolsover\",\n",
    "    \"E07000034\": \"Chesterfield\", \"E07000035\": \"Derbyshire Dales\", \"E07000036\": \"Erewash\", \"E07000037\": \"High Peak\", \"E07000038\": \"North East Derbyshire\",\n",
    "    \"E07000039\": \"South Derbyshire\", \"E07000040\": \"East Devon\", \"E07000041\": \"Exeter\", \"E07000042\": \"Mid Devon\", \"E07000043\": \"North Devon\",\n",
    "    \"E07000044\": \"South Hams\", \"E07000045\": \"Teignbridge\", \"E07000046\": \"Torridge\", \"E07000047\": \"West Devon\", \"E07000048\": \"Christchurch\",\n",
    "    \"E07000049\": \"East Dorset\", \"E07000050\": \"North Dorset\", \"E07000051\": \"Purbeck\", \"E07000052\": \"West Dorset\", \"E07000053\": \"Weymouth and Portland\",\n",
    "    \"E07000054\": \"Chester-le-Street\", \"E07000055\": \"Derwentside\", \"E07000056\": \"Durham\", \"E07000057\": \"Easington\", \"E07000058\": \"Sedgefield\",\n",
    "    \"E07000059\": \"Teesdale\", \"E07000060\": \"Wear Valley\", \"E07000061\": \"Eastbourne\", \"E07000062\": \"Hastings\", \"E07000063\": \"Lewes\", \"E07000064\": \"Rother\",\n",
    "    \"E07000065\": \"Wealden\", \"E07000066\": \"Basildon\", \"E07000067\": \"Braintree\", \"E07000068\": \"Brentwood\", \"E07000069\": \"Castle Point\", \"E07000070\": \"Chelmsford\",\n",
    "    \"E07000071\": \"Colchester\", \"E07000072\": \"Epping Forest\", \"E07000073\": \"Harlow\", \"E07000074\": \"Maldon\", \"E07000075\": \"Rochford\", \"E07000076\": \"Tendring\",\n",
    "    \"E07000077\": \"Uttlesford\", \"E07000078\": \"Cheltenham\", \"E07000079\": \"Cotswold\", \"E07000080\": \"Forest of Dean\", \"E07000081\": \"Gloucester\", \"E07000082\": \"Stroud\",\n",
    "    \"E07000083\": \"Tewkesbury\", \"E07000084\": \"Basingstoke and Deane\", \"E07000085\": \"East Hampshire\", \"E07000086\": \"Eastleigh\", \"E07000087\": \"Fareham\",\n",
    "    \"E07000088\": \"Gosport\", \"E07000089\": \"Hart\", \"E07000090\": \"Havant\", \"E07000091\": \"New Forest\", \"E07000092\": \"Rushmoor\", \"E07000093\": \"Test Valley\",\n",
    "    \"E07000094\": \"Winchester\", \"E07000095\": \"Broxbourne\", \"E07000096\": \"Dacorum\", \"E07000097\": \"East Hertfordshire\", \"E07000098\": \"Hertsmere\",\n",
    "    \"E07000099\": \"North Hertfordshire\", \"E07000100\": \"St Albans\", \"E07000101\": \"Stevenage\", \"E07000102\": \"Three Rivers\", \"E07000103\": \"Watford\",\n",
    "    \"E07000104\": \"Welwyn Hatfield\", \"E07000105\": \"Ashford\", \"E07000106\": \"Canterbury\", \"E07000107\": \"Dartford\", \"E07000108\": \"Dover\",\n",
    "    \"E07000109\": \"Gravesham\", \"E07000110\": \"Maidstone\", \"E07000111\": \"Sevenoaks\", \"E07000112\": \"Shepway\", \"E07000113\": \"Swale\", \"E07000114\": \"Thanet\",\n",
    "    \"E07000115\": \"Tonbridge and Malling\", \"E07000116\": \"Tunbridge Wells\", \"E07000117\": \"Burnley\", \"E07000118\": \"Chorley\", \"E07000119\": \"Fylde\",\n",
    "    \"E07000120\": \"Hyndburn\", \"E07000121\": \"Lancaster\", \"E07000122\": \"Pendle\", \"E07000123\": \"Preston\", \"E07000124\": \"Ribble Valley\",\n",
    "    \"E07000125\": \"Rossendale\", \"E07000126\": \"South Ribble\", \"E07000127\": \"West Lancashire\", \"E07000128\": \"Wyre\", \"E07000129\": \"Blaby\",\n",
    "    \"E07000130\": \"Charnwood\", \"E07000131\": \"Harborough\", \"E07000132\": \"Hinckley and Bosworth\", \"E07000133\": \"Melton\", \"E07000134\": \"North West Leicestershire\",\n",
    "    \"E07000135\": \"Oadby and Wigston\", \"E07000136\": \"Boston\", \"E07000137\": \"East Lindsey\", \"E07000138\": \"Lincoln\", \"E07000139\": \"North Kesteven\",\n",
    "    \"E07000140\": \"South Holland\", \"E07000141\": \"South Kesteven\", \"E07000142\": \"West Lindsey\", \"E07000143\": \"Breckland\", \"E07000144\": \"Broadland\",\n",
    "    \"E07000145\": \"Great Yarmouth\", \"E07000146\": \"King's Lynn and West Norfolk\", \"E07000147\": \"North Norfolk\", \"E07000148\": \"Norwich\",\n",
    "    \"E07000149\": \"South Norfolk\", \"E07000150\": \"Corby\", \"E07000151\": \"Daventry\", \"E07000152\": \"East Northamptonshire\", \"E07000153\": \"Kettering\",\n",
    "    \"E07000154\": \"Northampton\", \"E07000155\": \"South Northamptonshire\", \"E07000156\": \"Wellingborough\", \"E07000163\": \"Craven\", \"E07000164\": \"Hambleton\",\n",
    "    \"E07000165\": \"Harrogate\", \"E07000166\": \"Richmondshire\", \"E07000167\": \"Ryedale\", \"E07000168\": \"Scarborough\", \"E07000169\": \"Selby\",\n",
    "    \"E07000170\": \"Ashfield\", \"E07000171\": \"Bassetlaw\", \"E07000172\": \"Broxtowe\", \"E07000173\": \"Gedling\", \"E07000174\": \"Mansfield\",\n",
    "    \"E07000175\": \"Newark and Sherwood\", \"E07000176\": \"Rushcliffe\", \"E07000177\": \"Cherwell\", \"E07000178\": \"Oxford\", \"E07000179\": \"South Oxfordshire\",\n",
    "    \"E07000180\": \"Vale of White Horse\", \"E07000181\": \"West Oxfordshire\", \"E07000187\": \"Mendip\", \"E07000188\": \"Sedgemoor\", \"E07000189\": \"South Somerset\",\n",
    "    \"E07000190\": \"Taunton Deane\", \"E07000191\": \"West Somerset\", \"E07000192\": \"Cannock Chase\", \"E07000193\": \"East Staffordshire\", \"E07000194\": \"Lichfield\",\n",
    "    \"E07000195\": \"Newcastle-under-Lyme\", \"E07000196\": \"South Staffordshire\", \"E07000197\": \"Stafford\", \"E07000198\": \"Staffordshire Moorlands\",\n",
    "    \"E07000199\": \"Tamworth\", \"E07000200\": \"Babergh\", \"E07000201\": \"Forest Heath\", \"E07000202\": \"Ipswich\", \"E07000203\": \"Mid Suffolk\",\n",
    "    \"E07000204\": \"St Edmundsbury\", \"E07000205\": \"Suffolk Coastal\", \"E07000206\": \"Waveney\", \"E07000207\": \"Elmbridge\", \"E07000208\": \"Epsom and Ewell\",\n",
    "    \"E07000209\": \"Guildford\", \"E07000210\": \"Mole Valley\", \"E07000211\": \"Reigate and Banstead\", \"E07000212\": \"Runnymede\", \"E07000213\": \"Spelthorne\",\n",
    "    \"E07000214\": \"Surrey Heath\", \"E07000215\": \"Tandridge\", \"E07000216\": \"Waverley\", \"E07000217\": \"Woking\", \"E07000218\": \"North Warwickshire\",\n",
    "    \"E07000219\": \"Nuneaton and Bedworth\", \"E07000220\": \"Rugby\", \"E07000221\": \"Stratford-on-Avon\", \"E07000222\": \"Warwick\", \"E07000223\": \"Adur\",\n",
    "    \"E07000224\": \"Arun\", \"E07000225\": \"Chichester\", \"E07000226\": \"Crawley\", \"E07000227\": \"Horsham\", \"E07000228\": \"Mid Sussex\", \"E07000229\": \"Worthing\",\n",
    "    \"E07000234\": \"Bromsgrove\", \"E07000235\": \"Malvern Hills\", \"E07000236\": \"Redditch\", \"E07000237\": \"Worcester\", \"E07000238\": \"Wychavon\", \"E07000239\": \"Wyre Forest\",\n",
    "    \"E07000240\": \"St Albans\", \"E07000241\": \"Welwyn Hatfield\", \"E07000242\": \"East Hertfordshire\", \"E07000243\": \"Stevenage\", \"E07000244\": \"East Suffolk\",\n",
    "    \"E07000245\": \"West Suffolk\", \"E08000001\": \"Bolton\", \"E08000002\": \"Bury\", \"E08000003\": \"Manchester\", \"E08000004\": \"Oldham\", \"E08000005\": \"Rochdale\",\n",
    "    \"E08000006\": \"Salford\", \"E08000007\": \"Stockport\", \"E08000008\": \"Tameside\", \"E08000009\": \"Trafford\", \"E08000010\": \"Wigan\", \"E08000011\": \"Knowsley\",\n",
    "    \"E08000012\": \"Liverpool\", \"E08000013\": \"St. Helens\", \"E08000014\": \"Sefton\", \"E08000015\": \"Wirral\", \"E08000016\": \"Barnsley\", \"E08000017\": \"Doncaster\",\n",
    "    \"E08000018\": \"Rotherham\", \"E08000019\": \"Sheffield\", \"E08000020\": \"Gateshead\", \"E08000021\": \"Newcastle upon Tyne\", \"E08000022\": \"North Tyneside\",\n",
    "    \"E08000023\": \"South Tyneside\", \"E08000024\": \"Sunderland\", \"E08000025\": \"Birmingham\", \"E08000026\": \"Coventry\", \"E08000027\": \"Dudley\", \"E08000028\": \"Sandwell\",\n",
    "    \"E08000029\": \"Solihull\", \"E08000030\": \"Walsall\", \"E08000031\": \"Wolverhampton\", \"E08000032\": \"Bradford\", \"E08000033\": \"Calderdale\", \"E08000034\": \"Kirklees\",\n",
    "    \"E08000035\": \"Leeds\", \"E08000036\": \"Wakefield\", \"E08000037\": \"Gateshead\", \"E09000001\": \"City of London\", \"E09000002\": \"Barking and Dagenham\", \"E09000003\": \"Barnet\",\n",
    "    \"E09000004\": \"Bexley\", \"E09000005\": \"Brent\", \"E09000006\": \"Bromley\", \"E09000007\": \"Camden\", \"E09000008\": \"Croydon\", \"E09000009\": \"Ealing\",\n",
    "    \"E09000010\": \"Enfield\", \"E09000011\": \"Greenwich\", \"E09000012\": \"Hackney\", \"E09000013\": \"Hammersmith and Fulham\", \"E09000014\": \"Haringey\",\n",
    "    \"E09000015\": \"Harrow\", \"E09000016\": \"Havering\", \"E09000017\": \"Hillingdon\", \"E09000018\": \"Hounslow\", \"E09000019\": \"Islington\", \"E09000020\": \"Kensington and Chelsea\",\n",
    "    \"E09000021\": \"Kingston upon Thames\", \"E09000022\": \"Lambeth\", \"E09000023\": \"Lewisham\", \"E09000024\": \"Merton\", \"E09000025\": \"Newham\", \"E09000026\": \"Redbridge\",\n",
    "    \"E09000027\": \"Richmond upon Thames\", \"E09000028\": \"Southwark\", \"E09000029\": \"Sutton\", \"E09000030\": \"Tower Hamlets\", \"E09000031\": \"Waltham Forest\",\n",
    "    \"E09000032\": \"Wandsworth\", \"E09000033\": \"Westminster\", \"E10000004\": \"Cheshire\", \"EHEATHROW\": \"London Airport (Heathrow)\",\n",
    "    \"S12000005\": \"Clackmannanshire\", \"S12000006\": \"Dumfries and Galloway\", \"S12000008\": \"East Ayrshire\", \"S12000009\": \"East Dunbartonshire\",\n",
    "    \"S12000010\": \"East Lothian\", \"S12000011\": \"East Renfrewshire\", \"S12000013\": \"Comhairle nan Eilean Siar\", \"S12000014\": \"Falkirk\", \"S12000015\": \"Fife\",\n",
    "    \"S12000017\": \"Highland\", \"S12000018\": \"Inverclyde\", \"S12000019\": \"Midlothian\", \"S12000020\": \"Moray\", \"S12000021\": \"North Ayrshire\",\n",
    "    \"S12000023\": \"Orkney Islands\", \"S12000024\": \"Perth and Kinross\", \"S12000026\": \"Scottish Borders\", \"S12000027\": \"Shetland Islands\",\n",
    "    \"S12000028\": \"South Ayrshire\", \"S12000029\": \"South Lanarkshire\", \"S12000030\": \"Stirling\", \"S12000033\": \"Aberdeen City\", \"S12000034\": \"Aberdeenshire\",\n",
    "    \"S12000035\": \"Argyll and Bute\", \"S12000036\": \"City of Edinburgh\", \"S12000038\": \"Renfrewshire\", \"S12000039\": \"West Dunbartonshire\", \"S12000040\": \"West Lothian\",\n",
    "    \"S12000041\": \"Angus\", \"S12000042\": \"Dundee City\", \"S12000043\": \"Glasgow City\", \"S12000044\": \"North Lanarkshire\", \"S12000045\": \"East Dunbartonshire\",\n",
    "    \"S12000046\": \"Glasgow City\", \"S12000047\": \"Fife\", \"S12000048\": \"Perth and Kinross\", \"S12000049\": \"Glasgow City\", \"S12000050\": \"North Lanarkshire\",\n",
    "    \"W06000001\": \"Isle of Anglesey\", \"W06000002\": \"Gwynedd\", \"W06000003\": \"Conwy\", \"W06000004\": \"Denbighshire\", \"W06000005\": \"Flintshire\",\n",
    "    \"W06000006\": \"Wrexham\", \"W06000008\": \"Ceredigion\", \"W06000009\": \"Pembrokeshire\", \"W06000010\": \"Carmarthenshire\", \"W06000011\": \"Swansea\",\n",
    "    \"W06000012\": \"Neath Port Talbot\", \"W06000013\": \"Bridgend\", \"W06000014\": \"Vale of Glamorgan\", \"W06000015\": \"Cardiff\", \"W06000016\": \"Rhondda Cynon Taf\",\n",
    "    \"W06000018\": \"Caerphilly\", \"W06000019\": \"Blaenau Gwent\", \"W06000020\": \"Torfaen\", \"W06000021\": \"Monmouthshire\", \"W06000022\": \"Newport\", \"W06000023\": \"Powys\",\n",
    "    \"W06000024\": \"Merthyr Tydfil\"\n",
    "}\n",
    "\n",
    "collision['local_authority_ons_district'] = collision['local_authority_ons_district'].map(uk_admin_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1c3937-292d-4adf-b41a-46a634e71afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using map, lets create a 'region' column using the 'local_authority_district' column. This allows us to condense the categories in this column\n",
    "district_to_region = {\n",
    "    1: 'Greater London', 2: 'Greater London', 3: 'Greater London', 4: 'Greater London', 5: 'Greater London', 6: 'Greater London', 7: 'Greater London', \n",
    "    8: 'Greater London', 9: 'Greater London', 10: 'Greater London', 11: 'Greater London', 12: 'Greater London', 13: 'Greater London', 14: 'Greater London', \n",
    "    15: 'Greater London', 16: 'Greater London', 17: 'Greater London', 18: 'Greater London', 19: 'Greater London', 20: 'Greater London',\n",
    "    21: 'Greater London', 22: 'Greater London', 23: 'Greater London', 24: 'Greater London', 25: 'Greater London', 26: 'Greater London', 27: 'Greater London', \n",
    "    28: 'Greater London', 29: 'Greater London', 30: 'Greater London', 31: 'Greater London', 32: 'Greater London', 33: 'East of England', 38: 'South East', \n",
    "    40: 'South East', 57: 'Greater London',\n",
    "    \n",
    "    60: 'North West', 61: 'North West', 62: 'North West', 63: 'North West', 64: 'North West', 65: 'North West', 70: 'North West', 71: 'North West', 72: 'North West', \n",
    "    73: 'North West', 74: 'North West', 75: 'North West', 76: 'North West', 77: 'North West', 79: 'North West', 80: 'North West', 82: 'North West', 83: 'North West',\n",
    "    84: 'North West', 85: 'North West', 90: 'North West', 91: 'North West', 92: 'North West', 93: 'North West', 95: 'North West', 100: 'North West', 101: 'North West', \n",
    "    102: 'North West', 104: 'North West', 106: 'North West', 107: 'North West', 109: 'North West', 110: 'North West', 112: 'North West', 114: 'North West', 120: 'North West',\n",
    "    121: 'North West', 122: 'North West', 123: 'North West', 124: 'North West', 126: 'North West', 127: 'North West', 128: 'North West', 129: 'North West', 130: 'North West',\n",
    "\n",
    "    139: 'North East', 140: 'North East', 141: 'North East', 142: 'North East', 143: 'North East', 144: 'North East', 145: 'North East', 146: 'North East', 147: 'North East', \n",
    "    148: 'North East', 149: 'North East', 150: 'North East', 160: 'North East', 161: 'North East', 162: 'North East', 163: 'North East', 164: 'North East', 165: 'North East',\n",
    "    166: 'North East', 168: 'North East', 169: 'North East',\n",
    "\n",
    "    180: 'Yorkshire and the Humber', 181: 'Yorkshire and the Humber', 182: 'Yorkshire and the Humber', 184: 'Yorkshire and the Humber', 185: 'Yorkshire and the Humber', \n",
    "    186: 'Yorkshire and the Humber', 187: 'Yorkshire and the Humber', 189: 'Yorkshire and the Humber', 200: 'Yorkshire and the Humber', 202: 'Yorkshire and the Humber', \n",
    "    203: 'Yorkshire and the Humber', 204: 'Yorkshire and the Humber', 206: 'Yorkshire and the Humber', 210: 'Yorkshire and the Humber', 211: 'Yorkshire and the Humber', \n",
    "    213: 'Yorkshire and the Humber', 215: 'Yorkshire and the Humber', 220: 'Yorkshire and the Humber', 221: 'Yorkshire and the Humber', 224: 'Yorkshire and the Humber',\n",
    "    225: 'Yorkshire and the Humber', 226: 'Yorkshire and the Humber', 227: 'Yorkshire and the Humber', 228: 'Yorkshire and the Humber', 229: 'Yorkshire and the Humber', \n",
    "    230: 'Yorkshire and the Humber', 231: 'Yorkshire and the Humber', 232: 'Yorkshire and the Humber', 233: 'Yorkshire and the Humber', 240: 'Yorkshire and the Humber', \n",
    "    241: 'Yorkshire and the Humber', 243: 'Yorkshire and the Humber', 245: 'Yorkshire and the Humber',\n",
    "\n",
    "    250: 'West Midlands', 251: 'West Midlands', 252: 'West Midlands', 253: 'West Midlands', 254: 'West Midlands', 255: 'West Midlands', 256: 'West Midlands', 257: 'West Midlands', \n",
    "    258: 'West Midlands', 270: 'West Midlands', 271: 'West Midlands', 272: 'West Midlands', 273: 'West Midlands', 274: 'West Midlands', 275: 'West Midlands', 276: 'West Midlands', \n",
    "    277: 'West Midlands', 278: 'West Midlands', 279: 'West Midlands', 280: 'West Midlands', 281: 'West Midlands', 282: 'West Midlands', 283: 'West Midlands', 284: 'West Midlands', \n",
    "    285: 'West Midlands', 286: 'West Midlands', 290: 'West Midlands', 291: 'West Midlands', 292: 'West Midlands', 293: 'West Midlands', 294: 'West Midlands', 300: 'West Midlands', \n",
    "    302: 'West Midlands', 303: 'West Midlands', 305: 'West Midlands', 306: 'West Midlands', 307: 'West Midlands', 309: 'West Midlands',\n",
    "\n",
    "    320: 'East Midlands', 321: 'East Midlands', 322: 'East Midlands', 323: 'East Midlands', 324: 'East Midlands', 325: 'East Midlands', 327: 'East Midlands', 328: 'East Midlands', \n",
    "    329: 'East Midlands', 340: 'East Midlands', 341: 'East Midlands', 342: 'East Midlands', 343: 'East Midlands', 344: 'East Midlands', 345: 'East Midlands', 346: 'East Midlands', \n",
    "    347: 'East Midlands', 350: 'East Midlands', 351: 'East Midlands', 352: 'East Midlands', 353: 'East Midlands', 354: 'East Midlands', 355: 'East Midlands', 356: 'East Midlands',\n",
    "\n",
    "    360: 'East of England', 361: 'East of England', 362: 'East of England', 363: 'East of England', 364: 'East of England', 365: 'East of England', 366: 'East of England', \n",
    "    367: 'East of England', 368: 'East of England', 380: 'East of England', 381: 'East of England', 382: 'East of England', 383: 'East of England', 384: 'East of England', \n",
    "    385: 'East of England', 386: 'East of England', 390: 'East of England', 391: 'East of England', 392: 'East of England', 393: 'East of England', 394: 'East of England', \n",
    "    395: 'East of England', 400: 'East of England', 401: 'East of England', 402: 'East of England', 404: 'East of England', 405: 'East of England', 406: 'East of England', \n",
    "    407: 'East of England',\n",
    "\n",
    "    410: 'South East', 411: 'South East', 412: 'South East', 413: 'South East', 414: 'South East', 415: 'South East', 416: 'South East', 420: 'South East', 421: 'South East', \n",
    "    422: 'South East', 423: 'South East', 424: 'South East', 430: 'South East', 431: 'South East', 432: 'South East', 433: 'South East', 434: 'South East', 435: 'South East', \n",
    "    436: 'South East', 437: 'South East', 438: 'South East', 450: 'South East', 451: 'South East', 452: 'South East', 453: 'South East', 454: 'South East', 455: 'South East', \n",
    "    456: 'South East', 457: 'South East', 458: 'South East', 459: 'South East', 460: 'South East', 461: 'South East', 462: 'South East', 463: 'South East', 470: 'South East',\n",
    "    471: 'South East', 472: 'South East', 473: 'South East', 474: 'South East', 475: 'South East', 476: 'South East', 477: 'South East', 478: 'South East', 479: 'South East', \n",
    "    480: 'South East', 481: 'South East', 482: 'South East', 483: 'South East', 484: 'South East', 485: 'South East', 490: 'South East', 491: 'South East', 492: 'South East', \n",
    "    493: 'South East', 494: 'South East', 495: 'South East', 496: 'South East', 497: 'South East', 498: 'South East', 499: 'South East', 500: 'South East', 501: 'South East', \n",
    "    502: 'South East', 503: 'South East', 505:'South East',  510: 'South East', 511: 'South East', 512: 'South East', 513: 'South East', 514: 'South East', 515: 'South East', \n",
    "    516: 'South East', 517: 'South East', 518: 'South East', 530: 'South East', 531: 'South East', 532: 'South East', 533: 'South East', 534: 'South East', 535: 'South East', \n",
    "    536: 'South East', 537: 'South East', 538: 'South East', 539: 'South East', 540: 'South East', 541: 'South East', 542: 'South East', 543: 'South East', 544: 'South East', \n",
    "    550: 'South East', 551: 'South East', 552: 'South East', 553: 'South East', 554: 'South East', 555: 'South East', 556: 'South East', 557: 'South East', 558: 'South East', \n",
    "    559: 'South East', 560: 'South East', 562: 'South East', 563: 'South East', 564: 'South East', 565: 'South East', \n",
    "\n",
    "    570: 'South West', 580: 'South West', 581: 'South West', 582: 'South West', 583: 'South West', 584: 'South West', 585: 'South West', 586: 'South West', 587: 'South West', \n",
    "    588: 'South West', 589: 'South West', 590: 'South West', 591: 'South West', 592: 'South West', 593: 'South West', 594: 'South West', 595: 'South West', 596: 'South West',\n",
    "    599: 'South West', 600: 'South West', 601: 'South West', 602: 'South West', 603: 'South West', 604: 'South West', 605: 'South West', 606: 'South West', 607: 'South West', \n",
    "    608: 'South West', 609: 'South West', 610: 'South West', 611: 'South West', 612: 'South West', 620: 'South West', 621: 'South West', 622: 'South West', 623: 'South West', \n",
    "    624: 'South West', 625: 'South West', 630: 'South West', 631: 'South West', 632: 'South West', 633: 'South West', 634: 'South West', 635: 'South West', 640: 'South West', \n",
    "    641: 'South West', 642: 'South West', 643: 'South West', 644: 'South West', 645: 'South West', 646: 'South West', 647: 'South West',\n",
    "\n",
    "    660: 'Wales', 661: 'Wales', 662: 'Wales', 663: 'Wales', 664: 'Wales', 665: 'Wales', 666: 'Wales', 667: 'Wales', 668: 'Wales', 669: 'Wales', 680: 'Wales', 682: 'Wales', \n",
    "    683: 'Wales', 684: 'Wales', 685: 'Wales', 690: 'Wales', 692: 'Wales', 694: 'Wales', 695: 'Wales', 696: 'Wales', 698: 'Wales', 699: 'Wales', 701: 'Wales', 702: 'Wales',\n",
    "    703: 'Wales', 704: 'Wales', 705: 'Wales', 710: 'Wales', 711: 'Wales', 712: 'Wales', 713: 'Wales', 714: 'Wales', 715: 'Wales', 716: 'Wales', 717: 'Wales', 718: 'Wales', \n",
    "    720: 'Wales', 721: 'Wales', 722: 'Wales', 723: 'Wales', 724: 'Wales', 725: 'Wales', 730: 'Wales', 731: 'Wales', 732: 'Wales', 733: 'Wales', 734: 'Wales', 740: 'Wales',\n",
    "    741: 'Wales', 742: 'Wales', 743: 'Wales', 744: 'Wales', 745: 'Wales', 746: 'Wales', 750: 'Wales', 751: 'Wales', 752: 'Wales', 753: 'Wales',\n",
    "\n",
    "    801: 'Scotland', 802: 'Scotland', 803: 'Scotland', 804: 'Scotland', 805: 'Scotland', 806: 'Scotland', 807: 'Scotland', 808: 'Scotland', 809: 'Scotland', 810: 'Scotland', \n",
    "    811: 'Scotland', 812: 'Scotland', 813: 'Scotland', 814: 'Scotland', 815: 'Scotland', 816: 'Scotland', 817: 'Scotland', 818: 'Scotland', 819: 'Scotland', 821: 'Scotland', \n",
    "    822: 'Scotland', 823: 'Scotland', 824: 'Scotland', 825: 'Scotland', 826: 'Scotland', 827: 'Scotland', 828: 'Scotland', 829: 'Scotland', 830: 'Scotland', 831: 'Scotland', \n",
    "    833: 'Scotland', 834: 'Scotland', 835: 'Scotland', 836: 'Scotland', 837: 'Scotland', 838: 'Scotland', 839: 'Scotland', 840: 'Scotland', 841: 'Scotland', 842: 'Scotland', \n",
    "    843: 'Scotland', 844: 'Scotland', 845: 'Scotland', 846: 'Scotland', 847: 'Scotland', 848: 'Scotland', 849: 'Scotland', 850: 'Scotland', 851: 'Scotland', 852: 'Scotland', \n",
    "    853: 'Scotland', 854: 'Scotland', 856: 'Scotland', 857: 'Scotland', 858: 'Scotland', 859: 'Scotland', 910: 'Scotland', 911: 'Scotland', 912: 'Scotland', 913: 'Scotland', \n",
    "    914: 'Scotland', 915: 'Scotland', 916: 'Scotland', 917: 'Scotland', 918: 'Scotland', 919: 'Scotland', 920: 'Scotland', 921: 'Scotland', 922: 'Scotland', 923: 'Scotland', \n",
    "    924: 'Scotland', 925: 'Scotland', 926: 'Scotland', 927: 'Scotland', 928: 'Scotland', 929: 'Scotland', 930: 'Scotland', 931: 'Scotland', 932: 'Scotland', 933: 'Scotland', \n",
    "    934: 'Scotland', 935: 'Scotland', 936: 'Scotland', 937: 'Scotland', 938: 'Scotland', 939: 'Scotland', 940: 'Scotland', 941: 'Scotland',\n",
    "\n",
    "    -1.0:'Unknown'\n",
    "}\n",
    "\n",
    "collision['region'] = collision['local_authority_district'].map(district_to_region)\n",
    "\n",
    "#Now we can drop the 'local_authority_district' column\n",
    "collision = collision.drop(columns = 'local_authority_district', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ccc1102-2e81-41a4-9b9b-5ce7af753c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Havering', 'Redbridge', 'Tower Hamlets', 'Westminster', 'Camden',\n",
       "       'Islington', 'Richmond upon Thames', 'Hackney', 'Southwark',\n",
       "       'St. Helens', 'Wirral', 'Knowsley', 'Stockport', 'Wigan', 'Bolton',\n",
       "       'Rochdale', 'Cheshire East', 'Cheshire West and Chester',\n",
       "       'Warrington', 'Halton', 'County Durham', 'Leeds', 'Doncaster',\n",
       "       'Coventry', 'Birmingham', 'Walsall', 'Newcastle-under-Lyme',\n",
       "       'South Staffordshire', 'Lichfield', 'Shropshire',\n",
       "       'Stratford-on-Avon', 'North Warwickshire', 'Warwick', 'Rushcliffe',\n",
       "       'Harborough', 'South Northamptonshire', 'Wellingborough',\n",
       "       'Daventry', 'East Cambridgeshire', 'Peterborough',\n",
       "       'Huntingdonshire', 'East Suffolk', 'West Suffolk',\n",
       "       'East Hertfordshire', 'North Hertfordshire', 'Braintree',\n",
       "       'Cherwell', 'Buckinghamshire', 'Windsor and Maidenhead',\n",
       "       'Milton Keynes', 'Rushmoor', 'Mid Sussex', 'Chichester',\n",
       "       'City of London', 'Sedgemoor', 'South Somerset', 'Mendip',\n",
       "       'Taunton Deane', 'South Gloucestershire', 'West Somerset',\n",
       "       'Bath and North East Somerset', 'Swindon', 'Wiltshire',\n",
       "       'Caerphilly', 'Vale of Glamorgan', 'Swansea', 'Cardiff',\n",
       "       'Neath Port Talbot', 'Bridgend', 'Rhondda Cynon Taf',\n",
       "       'Merthyr Tydfil', 'Powys', 'Carmarthenshire', 'Ceredigion',\n",
       "       'Barnet', 'Lambeth', 'Kensington and Chelsea', 'Hounslow',\n",
       "       'Haringey', 'Sutton', 'Kingston upon Thames', 'Brent', 'Bexley',\n",
       "       'Bromley', 'Barking and Dagenham', 'Ealing', 'Wandsworth',\n",
       "       'Merton', 'Hammersmith and Fulham', 'Lewisham', 'Croydon',\n",
       "       'Newham', 'Greenwich', 'Enfield', 'Harrow', 'Hillingdon',\n",
       "       'Waltham Forest', 'London Airport (Heathrow)', 'Carlisle',\n",
       "       'South Lakeland', 'Allerdale', 'Eden', 'Barrow-in-Furness',\n",
       "       'Copeland', 'Lancaster', 'Fylde', 'Preston', 'Rossendale',\n",
       "       'Burnley', 'Blackpool', 'Ribble Valley', 'Wyre',\n",
       "       'Blackburn with Darwen', 'Chorley', 'South Ribble', 'Pendle',\n",
       "       'Hyndburn', 'West Lancashire', 'Liverpool', 'Sefton', 'Manchester',\n",
       "       'Salford', 'Oldham', 'Trafford', 'Bury', 'Tameside', 'Gateshead',\n",
       "       'Newcastle upon Tyne', 'South Tyneside', 'Sunderland',\n",
       "       'Northumberland', 'North Tyneside', 'Darlington', 'Selby',\n",
       "       'Harrogate', 'York', 'Richmondshire', 'Hambleton', 'Ryedale',\n",
       "       'Craven', 'Scarborough', 'Calderdale', 'Bradford', 'Kirklees',\n",
       "       'Wakefield', 'Sheffield', 'Barnsley', 'Rotherham',\n",
       "       'Kingston upon Hull, City of', 'North Lincolnshire',\n",
       "       'East Riding of Yorkshire', 'North East Lincolnshire',\n",
       "       'Hartlepool', 'Redcar and Cleveland', 'Middlesbrough',\n",
       "       'Stockton-on-Tees', 'Sandwell', 'Wolverhampton', 'Dudley',\n",
       "       'Solihull', 'Staffordshire Moorlands', 'Stoke-on-Trent',\n",
       "       'Stafford', 'East Staffordshire', 'Cannock Chase', 'Tamworth',\n",
       "       'Malvern Hills', 'Bromsgrove', 'Wyre Forest', 'Telford and Wrekin',\n",
       "       'Herefordshire, County of', 'Wychavon', 'Worcester', 'Redditch',\n",
       "       'Rugby', 'Nuneaton and Bedworth', 'Erewash',\n",
       "       'North East Derbyshire', 'Derby', 'Derbyshire Dales', 'High Peak',\n",
       "       'Amber Valley', 'Bolsover', 'South Derbyshire', 'Chesterfield',\n",
       "       'Nottingham', 'Newark and Sherwood', 'Ashfield', 'Mansfield',\n",
       "       'Gedling', 'Bassetlaw', 'Broxtowe', 'South Kesteven',\n",
       "       'East Lindsey', 'North Kesteven', 'South Holland', 'Lincoln',\n",
       "       'West Lindsey', 'Boston', 'Blaby', 'Oadby and Wigston',\n",
       "       'North West Leicestershire', 'Melton', 'Rutland', 'Charnwood',\n",
       "       'Hinckley and Bosworth', 'Leicester', 'West Northamptonshire',\n",
       "       'North Northamptonshire', 'South Cambridgeshire', 'Fenland',\n",
       "       'Cambridge', 'Breckland', 'Norwich', 'South Norfolk',\n",
       "       \"King's Lynn and West Norfolk\", 'Great Yarmouth', 'North Norfolk',\n",
       "       'Broadland', 'Babergh', 'Ipswich', 'Mid Suffolk',\n",
       "       'Central Bedfordshire', 'Luton', 'Bedford', 'Stevenage', 'Watford',\n",
       "       'Welwyn Hatfield', 'St Albans', 'Dacorum', 'Broxbourne',\n",
       "       'Hertsmere', 'Three Rivers', 'Epping Forest', 'Basildon',\n",
       "       'Uttlesford', 'Tendring', 'Chelmsford', 'Southend-on-Sea',\n",
       "       'Colchester', 'Rochford', 'Castle Point', 'Harlow', 'Thurrock',\n",
       "       'Brentwood', 'Maldon', 'Oxford', 'Vale of White Horse',\n",
       "       'South Oxfordshire', 'Bracknell Forest', 'Reading',\n",
       "       'West Oxfordshire', 'West Berkshire', 'Wokingham', 'Slough',\n",
       "       'New Forest', 'Portsmouth', 'East Hampshire', 'Isle of Wight',\n",
       "       'Fareham', 'Eastleigh', 'Havant', 'Southampton', 'Winchester',\n",
       "       'Gosport', 'Test Valley', 'Basingstoke and Deane', 'Hart',\n",
       "       'Guildford', 'Waverley', 'Woking', 'Epsom and Ewell', 'Tandridge',\n",
       "       'Surrey Heath', 'Spelthorne', 'Runnymede', 'Mole Valley',\n",
       "       'Elmbridge', 'Reigate and Banstead', 'Maidstone', 'Dover',\n",
       "       'Ashford', 'Medway', 'Shepway', 'Gravesham', 'Swale', 'Thanet',\n",
       "       'Tonbridge and Malling', 'Canterbury', 'Sevenoaks', 'Dartford',\n",
       "       'Tunbridge Wells', 'Brighton and Hove', 'Eastbourne', 'Horsham',\n",
       "       'Lewes', 'Arun', 'Crawley', 'Wealden', 'Worthing', 'Rother',\n",
       "       'Hastings', 'Adur', 'Exeter', 'Torbay', 'Plymouth', 'North Devon',\n",
       "       'Cornwall', 'South Hams', 'Teignbridge', 'West Devon',\n",
       "       'East Devon', 'Torridge', 'Mid Devon', 'North Somerset',\n",
       "       'Bristol, City of', 'Tewkesbury', 'Gloucester', 'Stroud',\n",
       "       'Cotswold', 'Forest of Dean', 'Cheltenham',\n",
       "       'Dorset (excluding Christchurch)',\n",
       "       'Bournemouth, Christchurch and Poole', 'Conwy', 'Wrexham',\n",
       "       'Isle of Anglesey', 'Flintshire', 'Gwynedd', 'Denbighshire',\n",
       "       'Blaenau Gwent', 'Monmouthshire', 'Newport', 'Torfaen',\n",
       "       'Pembrokeshire', 'West Lothian', 'Glasgow City', 'Angus',\n",
       "       'Aberdeen City', 'Aberdeenshire', 'East Renfrewshire',\n",
       "       'Scottish Borders', 'Perth and Kinross', 'Highland',\n",
       "       'North Lanarkshire', 'South Lanarkshire', 'North Ayrshire',\n",
       "       'Stirling', 'East Lothian', 'Falkirk', 'City of Edinburgh',\n",
       "       'Inverclyde', 'Dundee City', 'Dumfries and Galloway',\n",
       "       'Argyll and Bute', 'Fife', 'Clackmannanshire', 'South Ayrshire',\n",
       "       'Renfrewshire', 'Moray', 'East Ayrshire', 'Midlothian',\n",
       "       'Comhairle nan Eilean Siar', 'East Dunbartonshire',\n",
       "       'West Dunbartonshire', 'Shetland Islands', 'Orkney Islands',\n",
       "       'Isles of Scilly'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown = collision[collision['region'] == 'Unknown']\n",
    "unknown['local_authority_ons_district'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b72a7d15-d323-4ee2-8bbe-306fabe956fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/yfq5dclx7cd6vx_pj9dj5d6m0000gn/T/ipykernel_50949/3170252522.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unknown['region'] = unknown['local_authority_ons_district'].map(districts_to_regions)\n"
     ]
    }
   ],
   "source": [
    "districts_to_regions = {\n",
    "    'Havering': 'London', 'Redbridge': 'London', 'Tower Hamlets': 'London', 'Westminster': 'London',\n",
    "    'Camden': 'London', 'Islington': 'London', 'Richmond upon Thames': 'London', 'Hackney': 'London',\n",
    "    'Southwark': 'London', 'St. Helens': 'North West', 'Wirral': 'North West', 'Knowsley': 'North West',\n",
    "    'Stockport': 'North West', 'Wigan': 'North West', 'Bolton': 'North West', 'Rochdale': 'North West',\n",
    "    'Cheshire East': 'North West', 'Cheshire West and Chester': 'North West', 'Warrington': 'North West', 'Halton': 'North West',\n",
    "    'County Durham': 'North East', 'Leeds': 'Yorkshire and the Humber', 'Doncaster': 'Yorkshire and the Humber', 'Coventry': 'West Midlands',\n",
    "    'Birmingham': 'West Midlands', 'Walsall': 'West Midlands', 'Newcastle-under-Lyme': 'West Midlands', 'South Staffordshire': 'West Midlands',\n",
    "    'Lichfield': 'West Midlands', 'Shropshire': 'West Midlands', 'Stratford-on-Avon': 'West Midlands', 'North Warwickshire': 'West Midlands',\n",
    "    'Warwick': 'West Midlands', 'Rushcliffe': 'East Midlands', 'Harborough': 'East Midlands', 'South Northamptonshire': 'East Midlands',\n",
    "    'Wellingborough': 'East Midlands', 'Daventry': 'East Midlands', 'East Cambridgeshire': 'East of England', 'Peterborough': 'East of England',\n",
    "    'Huntingdonshire': 'East of England', 'East Suffolk': 'East of England', 'West Suffolk': 'East of England', 'East Hertfordshire': 'East of England',\n",
    "    'North Hertfordshire': 'East of England', 'Braintree': 'East of England', 'Cherwell': 'South East', 'Buckinghamshire': 'South East',\n",
    "    'Windsor and Maidenhead': 'South East', 'Milton Keynes': 'South East', 'Rushmoor': 'South East', 'Mid Sussex': 'South East',\n",
    "    'Chichester': 'South East', 'City of London': 'London', 'Sedgemoor': 'South West', 'South Somerset': 'South West',\n",
    "    'Mendip': 'South West', 'Taunton Deane': 'South West', 'South Gloucestershire': 'South West', 'West Somerset': 'South West',\n",
    "    'Bath and North East Somerset': 'South West', 'Swindon': 'South West', 'Wiltshire': 'South West', 'Caerphilly': 'Wales',\n",
    "    'Vale of Glamorgan': 'Wales', 'Swansea': 'Wales', 'Cardiff': 'Wales', 'Neath Port Talbot': 'Wales', 'Bridgend': 'Wales',\n",
    "    'Rhondda Cynon Taf': 'Wales', 'Merthyr Tydfil': 'Wales', 'Powys': 'Wales', 'Carmarthenshire': 'Wales',\n",
    "    'Ceredigion': 'Wales', 'Barnet': 'London', 'Lambeth': 'London', 'Kensington and Chelsea': 'London',\n",
    "    'Hounslow': 'London', 'Haringey': 'London', 'Sutton': 'London', 'Kingston upon Thames': 'London',\n",
    "    'Brent': 'London', 'Bexley': 'London', 'Bromley': 'London', 'Barking and Dagenham': 'London',\n",
    "    'Ealing': 'London', 'Wandsworth': 'London', 'Merton': 'London', 'Hammersmith and Fulham': 'London',\n",
    "    'Lewisham': 'London', 'Croydon': 'London', 'Newham': 'London', 'Greenwich': 'London',\n",
    "    'Enfield': 'London', 'Harrow': 'London', 'Hillingdon': 'London', 'Waltham Forest': 'London',\n",
    "    'London Airport (Heathrow)': 'London', 'Carlisle': 'North West', 'South Lakeland': 'North West', 'Allerdale': 'North West',\n",
    "    'Eden': 'North West', 'Barrow-in-Furness': 'North West', 'Copeland': 'North West', 'Lancaster': 'North West',\n",
    "    'Fylde': 'North West', 'Preston': 'North West', 'Rossendale': 'North West', 'Burnley': 'North West',\n",
    "    'Blackpool': 'North West', 'Ribble Valley': 'North West', 'Wyre': 'North West', 'Blackburn with Darwen': 'North West',\n",
    "    'Chorley': 'North West', 'South Ribble': 'North West', 'Pendle': 'North West', 'Hyndburn': 'North West',\n",
    "    'West Lancashire': 'North West', 'Liverpool': 'North West', 'Sefton': 'North West', 'Manchester': 'North West',\n",
    "    'Salford': 'North West', 'Oldham': 'North West', 'Trafford': 'North West', 'Bury': 'North West',\n",
    "    'Tameside': 'North West', 'Gateshead': 'North East', 'Newcastle upon Tyne': 'North East', 'South Tyneside': 'North East',\n",
    "    'Sunderland': 'North East', 'Northumberland': 'North East', 'North Tyneside': 'North East', 'Darlington': 'North East',\n",
    "    'Selby': 'Yorkshire and the Humber', 'Harrogate': 'Yorkshire and the Humber', 'York': 'Yorkshire and the Humber', 'Richmondshire': 'Yorkshire and the Humber',\n",
    "    'Hambleton': 'Yorkshire and the Humber', 'Ryedale': 'Yorkshire and the Humber', 'Craven': 'Yorkshire and the Humber', 'Scarborough': 'Yorkshire and the Humber',\n",
    "    'Calderdale': 'Yorkshire and the Humber', 'Bradford': 'Yorkshire and the Humber', 'Kirklees': 'Yorkshire and the Humber', 'Wakefield': 'Yorkshire and the Humber',\n",
    "    'Sheffield': 'Yorkshire and the Humber', 'Barnsley': 'Yorkshire and the Humber', 'Rotherham': 'Yorkshire and the Humber', 'Kingston upon Hull, City of': 'Yorkshire and the Humber',\n",
    "    'North Lincolnshire': 'Yorkshire and the Humber', 'East Riding of Yorkshire': 'Yorkshire and the Humber', 'North East Lincolnshire': 'Yorkshire and the Humber', 'Hartlepool': 'North East',\n",
    "    'Redcar and Cleveland': 'North East', 'Middlesbrough': 'North East', 'Stockton-on-Tees': 'North East', 'Sandwell': 'West Midlands',\n",
    "    'Wolverhampton': 'West Midlands', 'Dudley': 'West Midlands', 'Solihull': 'West Midlands', 'Staffordshire Moorlands': 'West Midlands',\n",
    "    'Stoke-on-Trent': 'West Midlands', 'Stafford': 'West Midlands', 'East Staffordshire': 'West Midlands', 'Cannock Chase': 'West Midlands',\n",
    "    'Tamworth': 'West Midlands', 'Malvern Hills': 'West Midlands', 'Bromsgrove': 'West Midlands', 'Wyre Forest': 'West Midlands',\n",
    "    'Telford and Wrekin': 'West Midlands', 'Herefordshire, County of': 'West Midlands', 'Wychavon': 'West Midlands', 'Worcester': 'West Midlands',\n",
    "    'Redditch': 'West Midlands', 'Rugby': 'West Midlands', 'Nuneaton and Bedworth': 'West Midlands', 'Erewash': 'East Midlands',\n",
    "    'North East Derbyshire': 'East Midlands', 'Derby': 'East Midlands', 'Derbyshire Dales': 'East Midlands', 'High Peak': 'East Midlands',\n",
    "    'Amber Valley': 'East Midlands', 'Bolsover': 'East Midlands', 'South Derbyshire': 'East Midlands', 'Chesterfield': 'East Midlands',\n",
    "    'Nottingham': 'East Midlands', 'Newark and Sherwood': 'East Midlands', 'Ashfield': 'East Midlands', 'Mansfield': 'East Midlands',\n",
    "    'Gedling': 'East Midlands', 'Bassetlaw': 'East Midlands', 'Broxtowe': 'East Midlands', 'South Kesteven': 'East Midlands',\n",
    "    'East Lindsey': 'East Midlands', 'North Kesteven': 'East Midlands', 'South Holland': 'East Midlands', 'Lincoln': 'East Midlands',\n",
    "    'West Lindsey': 'East Midlands', 'Boston': 'East Midlands', 'Blaby': 'East Midlands', 'Oadby and Wigston': 'East Midlands',\n",
    "    'North West Leicestershire': 'East Midlands', 'Melton': 'East Midlands', 'Rutland': 'East Midlands', 'Charnwood': 'East Midlands',\n",
    "    'Hinckley and Bosworth': 'East Midlands', 'Leicester': 'East Midlands', 'West Northamptonshire': 'East Midlands', 'North Northamptonshire': 'East Midlands',\n",
    "    'South Cambridgeshire': 'East of England', 'Fenland': 'East of England', 'Cambridge': 'East of England', 'Breckland': 'East of England',\n",
    "    'Norwich': 'East of England', 'South Norfolk': 'East of England', \"King's Lynn and West Norfolk\": 'East of England', 'Great Yarmouth': 'East of England',\n",
    "    'North Norfolk': 'East of England', 'Broadland': 'East of England', 'Babergh': 'East of England', 'Ipswich': 'East of England',\n",
    "    'Mid Suffolk': 'East of England', 'Central Bedfordshire': 'East of England', 'Luton': 'East of England', 'Bedford': 'East of England',\n",
    "    'Stevenage': 'East of England', 'Watford': 'East of England', 'Welwyn Hatfield': 'East of England', 'St Albans': 'East of England',\n",
    "    'Dacorum': 'East of England', 'Broxbourne': 'East of England', 'Hertsmere': 'East of England', 'Three Rivers': 'East of England',\n",
    "    'Epping Forest': 'East of England', 'Basildon': 'East of England', 'Uttlesford': 'East of England', 'Tendring': 'East of England',\n",
    "    'Chelmsford': 'East of England', 'Southend-on-Sea': 'East of England', 'Colchester': 'East of England', 'Rochford': 'East of England',\n",
    "    'Castle Point': 'East of England', 'Harlow': 'East of England', 'Thurrock': 'East of England', 'Brentwood': 'East of England',\n",
    "    'Maldon': 'East of England', 'Oxford': 'South East', 'Vale of White Horse': 'South East', 'South Oxfordshire': 'South East',\n",
    "    'Bracknell Forest': 'South East', 'Reading': 'South East', 'West Oxfordshire': 'South East', 'West Berkshire': 'South East',\n",
    "    'Wokingham': 'South East', 'Slough': 'South East', 'New Forest': 'South East', 'Portsmouth': 'South East',\n",
    "    'East Hampshire': 'South East', 'Isle of Wight': 'South East', 'Fareham': 'South East', 'Eastleigh': 'South East',\n",
    "    'Havant': 'South East', 'Southampton': 'South East', 'Winchester': 'South East', 'Gosport': 'South East',\n",
    "    'Test Valley': 'South East', 'Basingstoke and Deane': 'South East', 'Hart': 'South East', 'Guildford': 'South East',\n",
    "    'Waverley': 'South East', 'Woking': 'South East', 'Epsom and Ewell': 'South East', 'Tandridge': 'South East',\n",
    "    'Surrey Heath': 'South East', 'Spelthorne': 'South East', 'Runnymede': 'South East', 'Mole Valley': 'South East',\n",
    "    'Elmbridge': 'South East', 'Reigate and Banstead': 'South East', 'Maidstone': 'South East', 'Dover': 'South East',\n",
    "    'Ashford': 'South East', 'Medway': 'South East', 'Shepway': 'South East', 'Gravesham': 'South East',\n",
    "    'Swale': 'South East', 'Thanet': 'South East', 'Tonbridge and Malling': 'South East', 'Canterbury': 'South East',\n",
    "    'Sevenoaks': 'South East', 'Dartford': 'South East', 'Tunbridge Wells': 'South East', 'Brighton and Hove': 'South East',\n",
    "    'Eastbourne': 'South East', 'Horsham': 'South East', 'Lewes': 'South East', 'Arun': 'South East',\n",
    "    'Crawley': 'South East', 'Wealden': 'South East', 'Worthing': 'South East', 'Rother': 'South East',\n",
    "    'Hastings': 'South East', 'Adur': 'South East', 'Exeter': 'South West', 'Torbay': 'South West',\n",
    "    'Plymouth': 'South West', 'North Devon': 'South West', 'Cornwall': 'South West', 'South Hams': 'South West',\n",
    "    'Teignbridge': 'South West', 'West Devon': 'South West', 'East Devon': 'South West', 'Torridge': 'South West',\n",
    "    'Mid Devon': 'South West', 'North Somerset': 'South West', 'Bristol, City of': 'South West', 'Tewkesbury': 'South West',\n",
    "    'Gloucester': 'South West', 'Stroud': 'South West', 'Cotswold': 'South West', 'Forest of Dean': 'South West',\n",
    "    'Cheltenham': 'South West', 'Dorset (excluding Christchurch)': 'South West', 'Bournemouth, Christchurch and Poole': 'South West', 'Conwy': 'Wales',\n",
    "    'Wrexham': 'Wales', 'Isle of Anglesey': 'Wales', 'Flintshire': 'Wales', 'Gwynedd': 'Wales',\n",
    "    'Denbighshire': 'Wales', 'Blaenau Gwent': 'Wales', 'Monmouthshire': 'Wales', 'Newport': 'Wales',\n",
    "    'Torfaen': 'Wales', 'Pembrokeshire': 'Wales', 'West Lothian': 'Scotland', 'Glasgow City': 'Scotland',\n",
    "    'Angus': 'Scotland', 'Aberdeen City': 'Scotland', 'Aberdeenshire': 'Scotland', 'East Renfrewshire': 'Scotland',\n",
    "    'Scottish Borders': 'Scotland', 'Perth and Kinross': 'Scotland', 'Highland': 'Scotland', 'North Lanarkshire': 'Scotland',\n",
    "    'South Lanarkshire': 'Scotland', 'North Ayrshire': 'Scotland', 'Stirling': 'Scotland', 'East Lothian': 'Scotland',\n",
    "    'Falkirk': 'Scotland', 'City of Edinburgh': 'Scotland', 'Inverclyde': 'Scotland', 'Dundee City': 'Scotland',\n",
    "    'Dumfries and Galloway': 'Scotland', 'Argyll and Bute': 'Scotland', 'Fife': 'Scotland', 'Clackmannanshire': 'Scotland',\n",
    "    'South Ayrshire': 'Scotland', 'Renfrewshire': 'Scotland', 'Moray': 'Scotland', 'East Ayrshire': 'Scotland',\n",
    "    'Midlothian': 'Scotland', 'Comhairle nan Eilean Siar': 'Scotland', 'East Dunbartonshire': 'Scotland', 'West Dunbartonshire': 'Scotland',\n",
    "    'Shetland Islands': 'Scotland', 'Orkney Islands': 'Scotland', 'Isles of Scilly': 'South West'\n",
    "}\n",
    "\n",
    "unknown['region'] = unknown['local_authority_ons_district'].map(districts_to_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82614788-8d36-4076-b67d-439747ef69d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "collision = collision[collision['region'] != 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6817a5c-e2df-40bf-98bb-feb9a5ea7c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collision = pd.concat([collision, unknown], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "170c46c8-e365-4a23-b829-71144bfbcaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accident_index</th>\n",
       "      <th>accident_year</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>accident_severity</th>\n",
       "      <th>date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time</th>\n",
       "      <th>local_authority_ons_district</th>\n",
       "      <th>accident_month</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018010080971</td>\n",
       "      <td>2018</td>\n",
       "      <td>-0.139737</td>\n",
       "      <td>51.524587</td>\n",
       "      <td>Minor Injuries</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Monday</td>\n",
       "      <td>01:30</td>\n",
       "      <td>Camden</td>\n",
       "      <td>January</td>\n",
       "      <td>Greater London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018010080973</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.046471</td>\n",
       "      <td>51.539651</td>\n",
       "      <td>Minor Injuries</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Monday</td>\n",
       "      <td>00:50</td>\n",
       "      <td>Newham</td>\n",
       "      <td>January</td>\n",
       "      <td>Greater London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018010080974</td>\n",
       "      <td>2018</td>\n",
       "      <td>-0.102474</td>\n",
       "      <td>51.529746</td>\n",
       "      <td>Minor Injuries</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Monday</td>\n",
       "      <td>00:45</td>\n",
       "      <td>Islington</td>\n",
       "      <td>January</td>\n",
       "      <td>Greater London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018010080981</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.037828</td>\n",
       "      <td>51.530179</td>\n",
       "      <td>Seriously Injuries</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Monday</td>\n",
       "      <td>03:00</td>\n",
       "      <td>Newham</td>\n",
       "      <td>January</td>\n",
       "      <td>Greater London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018010080982</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.065781</td>\n",
       "      <td>51.469258</td>\n",
       "      <td>Seriously Injuries</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Monday</td>\n",
       "      <td>02:20</td>\n",
       "      <td>Greenwich</td>\n",
       "      <td>January</td>\n",
       "      <td>Greater London</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accident_index  accident_year longitude   latitude   accident_severity  \\\n",
       "0  2018010080971           2018 -0.139737  51.524587      Minor Injuries   \n",
       "1  2018010080973           2018  0.046471  51.539651      Minor Injuries   \n",
       "2  2018010080974           2018 -0.102474  51.529746      Minor Injuries   \n",
       "3  2018010080981           2018  0.037828  51.530179  Seriously Injuries   \n",
       "4  2018010080982           2018  0.065781  51.469258  Seriously Injuries   \n",
       "\n",
       "        date day_of_week   time local_authority_ons_district accident_month  \\\n",
       "0 2018-01-01      Monday  01:30                       Camden        January   \n",
       "1 2018-01-01      Monday  00:50                       Newham        January   \n",
       "2 2018-01-01      Monday  00:45                    Islington        January   \n",
       "3 2018-01-01      Monday  03:00                       Newham        January   \n",
       "4 2018-01-01      Monday  02:20                    Greenwich        January   \n",
       "\n",
       "           region  \n",
       "0  Greater London  \n",
       "1  Greater London  \n",
       "2  Greater London  \n",
       "3  Greater London  \n",
       "4  Greater London  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eae6098-2261-4b1e-9b21-4cd7bd62105d",
   "metadata": {},
   "source": [
    "#### Vehicle Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5168f50a-5fe5-4259-b675-402228f7883a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 990153 entries, 0 to 193544\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   accident_index      990153 non-null  object\n",
      " 1   vehicle_type        990153 non-null  int64 \n",
      " 2   sex_of_driver       990153 non-null  int64 \n",
      " 3   age_band_of_driver  990153 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 37.8+ MB\n"
     ]
    }
   ],
   "source": [
    "vehicle.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9f89982-bc10-487a-b33f-24c8a0dd0bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accident_index', 'vehicle_type', 'sex_of_driver',\n",
       "       'age_band_of_driver'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b89ccef0-43f4-4347-950d-829527acadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_vehicle_type(df):\n",
    "    vehicle_type_mapping = {\n",
    "        -1:'Unknown',\n",
    "        1:'Bicycle',\n",
    "        2:'Bicycle',\n",
    "        3:'Motorcycle',\n",
    "        4:'Motorcycle',\n",
    "        5:'Motorcycle',\n",
    "        8:'Car',\n",
    "        9:'Car',\n",
    "        10:'Other',\n",
    "        11:'Other',\n",
    "        16:'Other',\n",
    "        17:'Other',\n",
    "        18:'Other',\n",
    "        19:'Other',\n",
    "        20:'Other',\n",
    "        21:'Other',\n",
    "        22:'Bicycle',\n",
    "        23:'Motorcycle',\n",
    "        90:'Other',\n",
    "        97:'Motorcycle',\n",
    "        98:'Other',\n",
    "        99:'Unknown'\n",
    "    }\n",
    "\n",
    "    df['vehicle_type'] = df['vehicle_type'].map(vehicle_type_mapping)\n",
    "\n",
    "    return df\n",
    "\n",
    "vehicle = clean_vehicle_type(vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "adf52449-18b0-4185-a01a-ff7e24b47fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Car', 'Other', 'Bicycle', 'Motorcycle', 'Unknown'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle['vehicle_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8db7986b-77c8-40bf-8c6a-d8626c583746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the categories associated with the 'sex_of_driver' column\n",
    "def clean_gender_column(df, column_name):\n",
    "    gender_mapping = {\n",
    "        -1:'Unknown',\n",
    "        1:'Male',\n",
    "        2:'Female',\n",
    "        3:'Unknown',\n",
    "        9:'Unknown'\n",
    "    }\n",
    "\n",
    "    df[column_name] = df[column_name].map(gender_mapping)\n",
    "\n",
    "    return df\n",
    "\n",
    "vehicle = clean_gender_column(vehicle, 'sex_of_driver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35014fbb-46af-4f65-88d7-dae4d57af3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  8, -1,  7,  5,  9, 10, 11,  4,  3,  1,  2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle['age_band_of_driver'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adf7689f-943c-44c6-8da9-37d05f8355a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the categories associated with the 'age_band_of_driver' column\n",
    "def clean_age_band(df, column_name):\n",
    "    age_band_mapping = {\n",
    "        -1:'Unknown',\n",
    "        1:'0-5',\n",
    "        2:'6-10',\n",
    "        3:'11-15',\n",
    "        4:'16-20',\n",
    "        5:'21-25',\n",
    "        6:'26-35',\n",
    "        7:'36-45',\n",
    "        8:'46-55',\n",
    "        9:'56-65',\n",
    "        10:'66-75',\n",
    "        11:'75+'\n",
    "    }\n",
    "\n",
    "    df[column_name] = df[column_name].map(age_band_mapping)\n",
    "\n",
    "    return df\n",
    "\n",
    "vehicle = clean_age_band(vehicle, 'age_band_of_driver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a54251df-2117-4e27-84df-74288e784930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accident_index</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>sex_of_driver</th>\n",
       "      <th>age_band_of_driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018010080971</td>\n",
       "      <td>Car</td>\n",
       "      <td>Male</td>\n",
       "      <td>26-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018010080971</td>\n",
       "      <td>Car</td>\n",
       "      <td>Male</td>\n",
       "      <td>46-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018010080973</td>\n",
       "      <td>Car</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018010080974</td>\n",
       "      <td>Car</td>\n",
       "      <td>Male</td>\n",
       "      <td>36-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018010080974</td>\n",
       "      <td>Car</td>\n",
       "      <td>Male</td>\n",
       "      <td>21-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accident_index vehicle_type sex_of_driver age_band_of_driver\n",
       "0  2018010080971          Car          Male              26-35\n",
       "1  2018010080971          Car          Male              46-55\n",
       "2  2018010080973          Car       Unknown            Unknown\n",
       "3  2018010080974          Car          Male              36-45\n",
       "4  2018010080974          Car          Male              21-25"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a30c17-a501-4e89-be61-c1b754a7d1e3",
   "metadata": {},
   "source": [
    "#### Casualty Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8b289e4-c3fa-489c-ac7e-e6d7af4ea526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 693028 entries, 0 to 135479\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype \n",
      "---  ------                --------------   ----- \n",
      " 0   accident_index        693028 non-null  object\n",
      " 1   casualty_class        693028 non-null  int64 \n",
      " 2   sex_of_casualty       693028 non-null  int64 \n",
      " 3   age_band_of_casualty  693028 non-null  int64 \n",
      " 4   casualty_severity     693028 non-null  int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 31.7+ MB\n"
     ]
    }
   ],
   "source": [
    "casualty.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0a569da-12c6-4204-ada9-09656b0c9299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accident_index', 'casualty_class', 'sex_of_casualty',\n",
       "       'age_band_of_casualty', 'casualty_severity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casualty.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23ea0d21-9a85-4935-a7d1-1357c2c82b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the categories associated with the 'casualty_type' column\n",
    "def clean_casualty_class(df, column_name):\n",
    "    casualty_class_mapping = {\n",
    "        1:'Driver',\n",
    "        2:'Passenger',\n",
    "        3:'Pedestrian'\n",
    "    }\n",
    "\n",
    "    df[column_name] = df[column_name].map(casualty_class_mapping)\n",
    "\n",
    "    return df\n",
    "\n",
    "casualty = clean_casualty_class(casualty, 'casualty_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7d76eff-b5c5-4952-8adc-c9c50fe31f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can clean the 'sex_of_casualty' column using the 'clean_gender_column' function defined previously\n",
    "casualty = clean_gender_column(casualty, 'sex_of_casualty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "489953f3-fe5a-4367-9218-1517ef96ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Likewise, we will clean the 'age_band_of_casualty' column using the 'clean_age_band' function\n",
    "casualty = clean_age_band(casualty, 'age_band_of_casualty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07e538df-b70b-40ff-b690-a6684830b873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accident_index</th>\n",
       "      <th>casualty_class</th>\n",
       "      <th>sex_of_casualty</th>\n",
       "      <th>age_band_of_casualty</th>\n",
       "      <th>casualty_severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018010080971</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>Female</td>\n",
       "      <td>46-55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018010080971</td>\n",
       "      <td>Driver</td>\n",
       "      <td>Male</td>\n",
       "      <td>46-55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018010080973</td>\n",
       "      <td>Pedestrian</td>\n",
       "      <td>Male</td>\n",
       "      <td>26-35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018010080974</td>\n",
       "      <td>Driver</td>\n",
       "      <td>Male</td>\n",
       "      <td>36-45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018010080981</td>\n",
       "      <td>Driver</td>\n",
       "      <td>Male</td>\n",
       "      <td>26-35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accident_index casualty_class sex_of_casualty age_band_of_casualty  \\\n",
       "0  2018010080971      Passenger          Female                46-55   \n",
       "1  2018010080971         Driver            Male                46-55   \n",
       "2  2018010080973     Pedestrian            Male                26-35   \n",
       "3  2018010080974         Driver            Male                36-45   \n",
       "4  2018010080981         Driver            Male                26-35   \n",
       "\n",
       "   casualty_severity  \n",
       "0                  3  \n",
       "1                  3  \n",
       "2                  3  \n",
       "3                  3  \n",
       "4                  2  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casualty.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58431576-6398-478a-a1f3-d5329e7d2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_casualty_severity(df):\n",
    "    \"\"\"\n",
    "    Clean the 'accident_severity' column by replacing the numbers with a categorical variable to give it some meaning.'\n",
    "    \"\"\"\n",
    "    \n",
    "    #Mapping dictionary to regroup accident severity \n",
    "    accident_severity_mapping = {\n",
    "        1.0:'fatal',\n",
    "        2.0:'Seriously Injuries',\n",
    "        3.0:'Minor Injuries'\n",
    "    }\n",
    "\n",
    "    #Map values using the mapping dictionary\n",
    "    df['casualty_severity'] = df['casualty_severity'].map(accident_severity_mapping)\n",
    "\n",
    "    return df\n",
    "casualty = clean_casualty_severity(casualty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb81c19e-08db-406f-aada-ab126eaefdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will drop the 'date' column\n",
    "collision = collision.drop(columns = 'date', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2406b0b3-db81-417b-8321-d9b571f55234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accident_index                  object\n",
       "accident_year                    int64\n",
       "longitude                       object\n",
       "latitude                        object\n",
       "accident_severity               object\n",
       "day_of_week                     object\n",
       "time                            object\n",
       "local_authority_ons_district    object\n",
       "accident_month                  object\n",
       "region                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afac75ab-038c-4ba4-8f6f-182045d11659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(538461, 10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7daa4f-490c-45aa-96ba-7182e1293c2f",
   "metadata": {},
   "source": [
    "### Additional Data Cleaning Prior to Import to mySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3687581-bca9-4d8b-a765-7b9235258fad",
   "metadata": {},
   "source": [
    "In order to import the tables into the mySQL database, further cleaning needs to be done to specific rows for Python to allow for exporting of the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b04903a-e9ed-471f-8535-e1aa909ea3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a copy of the original collision df\n",
    "collision_copy = collision.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "25ee39de-c135-4779-9d7b-0fa0b61c3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to convert the 'accident_index' column into an integer, we need to remove instances where there are letters in the 'accident_index'\n",
    "pattern = r'[A-Za-z]'\n",
    "\n",
    "# Filter rows based on the pattern\n",
    "mask = collision_copy['accident_index'].str.contains(pattern, na=False) == False\n",
    "# Print or further process ids_with_letter\n",
    "collision_copy = collision_copy[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a30a1190-e4c0-43cf-a10f-24d9d3cf87b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483654, 10)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2759982f-71bd-4c2d-9539-ba6fd93ec8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast the 'accident_index' as an integer\n",
    "collision_copy['accident_index'] = collision_copy['accident_index'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0a6d77e-8f18-4e4c-878f-61c3b0a6c38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(990153, 4)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee3373d4-5f41-4a5f-a482-8cea6da84b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a copy of the original vehicle df\n",
    "vehicle_copy = vehicle.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ceffdd8f-93b7-4e79-8410-e517802e0138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows from the 'accident_index' that were removed from the collision df\n",
    "pattern = r'[A-Za-z]'\n",
    "\n",
    "# Filter rows based on the pattern\n",
    "mask = vehicle_copy['accident_index'].str.contains(pattern, na=False) == False\n",
    "# Print or further process ids_with_letter\n",
    "vehicle_copy = vehicle_copy[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e69c967-6dc3-427d-8400-ba0718c40fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(890251, 4)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6bc059d-8cb4-48cb-9bfd-3f48c9de0d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast the 'accident_index' as an integer\n",
    "vehicle_copy['accident_index'] = vehicle_copy['accident_index'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9e510612-8257-4879-9c4e-174a30170830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(693028, 5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casualty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1eed8eee-31c7-4fa5-acae-3c3f206562eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a copy of the original casualty df\n",
    "casualty_copy = casualty.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "737c6491-85b7-44a6-8741-749aa1250ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows from the 'accident_index' that were removed from the collision df\n",
    "pattern = r'[A-Za-z]'\n",
    "\n",
    "# Filter rows based on the pattern\n",
    "mask = casualty_copy['accident_index'].str.contains(pattern, na=False) == False\n",
    "# Print or further process ids_with_letter\n",
    "casualty_copy = casualty_copy[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e9daf784-5775-4130-a94e-6befcce3972b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620425, 5)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casualty_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "810b244f-b326-41f4-95cc-3ef4a79de13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast the 'accident_index' as an integer\n",
    "casualty_copy['accident_index'] = casualty_copy['accident_index'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf410d17-a794-418d-a7c9-bd3154a94fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast the 'longitude' as an integer\n",
    "collision_copy['longitude'] = collision_copy['longitude'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6c0cd0e1-3761-4c8b-8c56-97c9cd73f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast the 'latitude' as an integer\n",
    "collision_copy['latitude'] = collision_copy['latitude'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "317e1553-88f8-4909-8b59-9070eb58a707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accident_index', 'accident_year', 'longitude', 'latitude',\n",
       "       'accident_severity', 'day_of_week', 'time',\n",
       "       'local_authority_ons_district', 'accident_month', 'region'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55416b95-caf6-4968-936e-4b12026fdb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows in which the value is 'Unknown' from the vehicle table\n",
    "vehicle_copy = vehicle_copy[vehicle_copy['vehicle_type'] != 'Unknown']\n",
    "vehicle_copy = vehicle_copy[vehicle_copy['sex_of_driver'] != 'Unknown']\n",
    "vehicle_copy = vehicle_copy[vehicle_copy['age_band_of_driver'] != 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6a00286c-506d-46fd-aea9-3da5d2b1e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows in which the value is 'Unknown' from the casualty table\n",
    "casualty_copy = casualty_copy[casualty_copy['sex_of_casualty'] != 'Unknown']\n",
    "casualty_copy = casualty_copy[casualty_copy['age_band_of_casualty'] != 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "266ba485-62d8-42fa-a14e-95abcad1158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the clean dfs as a .csv file\n",
    "collision_copy.to_csv('collision.csv')\n",
    "vehicle_copy.to_csv('vehicle.csv')\n",
    "casualty_copy.to_csv('casualty.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b784b-9616-4da9-856d-446426229705",
   "metadata": {},
   "source": [
    "### Exporting the Tables to mySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a16bde9e-826b-46b3-b58b-5b752f87e8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "99cbfe4d-bca7-4cce-b7b7-ad995f9a7cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(mysql+pymysql://root:***@localhost/Final_Project)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd = \"Final_Project\" \n",
    "connection_string = 'mysql+pymysql://root:' + password + '@localhost/'+bd\n",
    "engine = create_engine(connection_string)\n",
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9ed9f02d-393a-40d3-b4f8-9c097f94337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "330a9ed8-d14a-4e6b-9bc3-aa5c8cdd35f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = engine.connect()\n",
    "    print(\"Connection established successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while connecting to the database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "474a2cc9-6d99-445a-8d60-4767bd8283eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = '../data/Clean/collision.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4c17aec2-d2c0-468d-803a-8818429034fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv_in_chunks(csv_file_path, engine, chunk_size=10000): \n",
    "    try: \n",
    "        chunk_iter = pd.read_csv(csv_file_path, chunksize=chunk_size, index_col=0)\n",
    "        for chunk in chunk_iter:\n",
    "            chunk['accident_index'] = pd.to_numeric(chunk['accident_index'], errors='raise')\n",
    "            chunk['longitude'] = pd.to_numeric(chunk['longitude'], errors='raise')\n",
    "            chunk['latitude'] = pd.to_numeric(chunk['latitude'], errors='raise')\n",
    "            chunk.to_sql(name='collision_info', con=engine, if_exists='append', index=False)\n",
    "            \n",
    "            print(f'{len(chunk)} rows inserted')\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"The CSV file is empty.\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing CSV file: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Data error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during CSV import: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9768d502-aa13-40d8-afcd-4d1e9975f16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "3654 rows inserted\n"
     ]
    }
   ],
   "source": [
    "# Call the function with the path to your CSV file and the engine\n",
    "import_csv_in_chunks(csv_file_path, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5349f933-550f-4a4b-ab5b-c15740318094",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = '../data/Clean/vehicle.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9e5067d8-ea07-4b04-b39f-de36b7a22326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv_in_chunks(csv_file_path, engine, chunk_size=10000): \n",
    "    try: \n",
    "        chunk_iter = pd.read_csv(csv_file_path, chunksize=chunk_size, index_col=0)\n",
    "        for chunk in chunk_iter:\n",
    "            chunk.to_sql(name='vehicle_info', con=engine, if_exists='append', index=False)\n",
    "            \n",
    "            print(f'{len(chunk)} rows inserted')\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"The CSV file is empty.\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing CSV file: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Data error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during CSV import: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "778e408b-a081-4023-af91-26c5482461a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "9960 rows inserted\n"
     ]
    }
   ],
   "source": [
    "import_csv_in_chunks(csv_file_path, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a896190f-1492-4538-a811-60db7ec1820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = '../data/Clean/casualty.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b52dac49-0ac0-46d9-a85b-01b31c8e6709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv_in_chunks(csv_file_path, engine, chunk_size=10000): \n",
    "    try: \n",
    "        chunk_iter = pd.read_csv(csv_file_path, chunksize=chunk_size, index_col=0)\n",
    "        for chunk in chunk_iter:\n",
    "            chunk.to_sql(name='casualty_info', con=engine, if_exists='append', index=False)\n",
    "            \n",
    "            print(f'{len(chunk)} rows inserted')\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"The CSV file is empty.\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing CSV file: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Data error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during CSV import: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "adc2a4ee-26ff-484c-9c05-45d6c89ec43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "10000 rows inserted\n",
      "4810 rows inserted\n"
     ]
    }
   ],
   "source": [
    "import_csv_in_chunks(csv_file_path, engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3_venv",
   "language": "python",
   "name": "p3_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
